{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7608cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "821145ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218a9ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=torch.load('train_features.pt')\n",
    "train_labels=torch.load('train_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ee4cc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1704759, 14])\n",
      "torch.Size([1704759])\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a08105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1704759, 15])\n"
     ]
    }
   ],
   "source": [
    "train = torch.cat([train_features, train_labels.reshape(-1,1)],1)\n",
    "print(train.shape)\n",
    "train = train[torch.randperm(train.size(0))] #shuffling dataset, parameter down need to be updated\n",
    "train_set = train[0:1500000,                            0:train.shape[1]-1]\n",
    "train_label = train[0:1500000,                          train.shape[1]-1]\n",
    "validation_set = train[1500000:1600000,                 0:train.shape[1]-1]\n",
    "validation_label = train[1500000:1600000,               train.shape[1]-1]\n",
    "test_set = train[1600000:train.shape[0],                0:train.shape[1]-1]\n",
    "test_label = train[1600000:train.shape[0],              train.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cd9c67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  8.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, 12.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [-0.5410, -1.9605, 10.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000, 11.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, 10.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [ 1.0912,  0.4009, 11.0000,  ...,  1.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47a60831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([104759, 14])\n"
     ]
    }
   ],
   "source": [
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd80065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may save them if you want\n",
    "torch.save(train_set,'train_set.pt')\n",
    "torch.save(train_label,'train_label.pt')\n",
    "torch.save(validation_set,'validation_set.pt')\n",
    "torch.save(validation_label,'validation_label.pt')\n",
    "torch.save(test_set,'test_set.pt')\n",
    "torch.save(test_label,'test_label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "622b7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_features\n",
    "del train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00a557eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(train_set.dtype)\n",
    "print(train_label.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76360068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1500000, 14])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61624c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c56a75fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10c3fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output_layer = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3450c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features in your data and the size of the hidden layer\n",
    "input_features = train_set.shape[1]\n",
    "hidden_size = 10\n",
    "\n",
    "# Initialize the model and move to the device\n",
    "model = MLP(input_features, hidden_size)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545717a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2ed2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y) + self.eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b8b993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 5\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "147bce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23438\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(train_set, train_label)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(validation_set, validation_label)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "print(len(train_loader))\n",
    "all_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c422f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():  # We don't need gradients for validation\n",
    "        for inputs, targets in val_loader:\n",
    "            # Move data to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Reshape targets\n",
    "            targets = torch.reshape(targets,(-1,1))\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = torch.sqrt(criterion(outputs, targets))  # RMSE\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "    # Return average loss\n",
    "    average_val_loss = running_val_loss / len(val_loader)\n",
    "    return average_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79e8f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        group_320_loss = 0\n",
    "        for i,(x, y) in enumerate(train_loader,0):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y = torch.reshape(y,(-1,1))\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = torch.sqrt(criterion(output, y))#RMSE\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            group_320_loss += loss.item()\n",
    "            if i%30==29:\n",
    "                all_losses.append(group_320_loss/6)\n",
    "        print(f\"Epoch: {epoch+1} Training Loss:{epoch_loss/len(train_loader)}\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val = x_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                y_val = torch.reshape(y_val,(-1,1))\n",
    "                preds = model(x_val)\n",
    "                val_loss += torch.sqrt(criterion(preds, y_val)).item() # RMSE\n",
    "        print(f\"Epoch: {epoch+1} Validation Loss:{val_loss/len(val_loader)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f95eb189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate 0.001 and weight decay 0.001\n",
      "Epoch: 1 Training Loss:580.4425179385236\n",
      "Epoch: 1 Validation Loss:580.8674465186765\n",
      "Epoch: 2 Training Loss:572.8421654940893\n",
      "Epoch: 2 Validation Loss:579.6405604698684\n",
      "Epoch: 3 Training Loss:572.714111680331\n",
      "Epoch: 3 Validation Loss:579.0455433948637\n",
      "Epoch: 4 Training Loss:572.0058029068036\n",
      "Epoch: 4 Validation Loss:580.1433473124538\n",
      "Epoch: 5 Training Loss:571.8242116036681\n",
      "Epoch: 5 Validation Loss:579.7281943215671\n",
      "Training with learning rate 0.001 and weight decay 0.0001\n",
      "Epoch: 1 Training Loss:582.6103047431864\n",
      "Epoch: 1 Validation Loss:580.798876351755\n",
      "Epoch: 2 Training Loss:573.129197310848\n",
      "Epoch: 2 Validation Loss:581.6621524081044\n",
      "Epoch: 3 Training Loss:573.0099476549709\n",
      "Epoch: 3 Validation Loss:580.419062970162\n",
      "Epoch: 4 Training Loss:572.5350274558726\n",
      "Epoch: 4 Validation Loss:580.4310192906239\n",
      "Epoch: 5 Training Loss:572.0992895680205\n",
      "Epoch: 5 Validation Loss:580.4896173751744\n",
      "Training with learning rate 0.001 and weight decay 1e-05\n",
      "Epoch: 1 Training Loss:582.3815550613306\n",
      "Epoch: 1 Validation Loss:580.7473652962302\n",
      "Epoch: 2 Training Loss:572.6893520744213\n",
      "Epoch: 2 Validation Loss:582.6384071354979\n",
      "Epoch: 5 Training Loss:571.8746787887535\n",
      "Epoch: 5 Validation Loss:581.3097974468483\n",
      "Training with learning rate 0.0001 and weight decay 0.001\n",
      "Epoch: 1 Training Loss:635.2188299800646\n",
      "Epoch: 1 Validation Loss:594.6042354727737\n",
      "Epoch: 2 Training Loss:578.0603218889142\n",
      "Epoch: 2 Validation Loss:582.018251229919\n",
      "Epoch: 3 Training Loss:574.903949611575\n",
      "Epoch: 3 Validation Loss:582.422832623248\n",
      "Epoch: 4 Training Loss:573.9132868388131\n",
      "Epoch: 4 Validation Loss:583.0372597175154\n",
      "Epoch: 5 Training Loss:573.745241614533\n",
      "Epoch: 5 Validation Loss:581.6247922149287\n",
      "Training with learning rate 0.0001 and weight decay 0.0001\n",
      "Epoch: 1 Training Loss:655.5099677541515\n",
      "Epoch: 1 Validation Loss:601.7777706641688\n",
      "Epoch: 2 Training Loss:585.0016047665463\n",
      "Epoch: 2 Validation Loss:586.0080646068258\n",
      "Epoch: 3 Training Loss:575.4403066816606\n",
      "Epoch: 3 Validation Loss:584.2954821449324\n",
      "Epoch: 4 Training Loss:574.7052547950592\n",
      "Epoch: 4 Validation Loss:582.2351460032789\n",
      "Epoch: 5 Training Loss:574.1984111500414\n",
      "Epoch: 5 Validation Loss:582.3042013860252\n",
      "Training with learning rate 0.0001 and weight decay 1e-05\n",
      "Epoch: 1 Training Loss:637.9529374662403\n",
      "Epoch: 1 Validation Loss:596.6991660715446\n",
      "Epoch: 2 Training Loss:581.6033967942017\n",
      "Epoch: 2 Validation Loss:584.5717594197981\n",
      "Epoch: 3 Training Loss:575.4747477255642\n",
      "Epoch: 3 Validation Loss:582.1315467136454\n",
      "Epoch: 4 Training Loss:574.1468577993253\n",
      "Epoch: 4 Validation Loss:581.4198384837165\n",
      "Epoch: 5 Training Loss:573.8799239066755\n",
      "Epoch: 5 Validation Loss:580.0125723635624\n",
      "Training with learning rate 1e-05 and weight decay 0.001\n",
      "Epoch: 1 Training Loss:923.8185778859635\n",
      "Epoch: 1 Validation Loss:904.425254074946\n",
      "Epoch: 2 Training Loss:823.9783835249535\n",
      "Epoch: 2 Validation Loss:733.3844538692931\n",
      "Epoch: 3 Training Loss:640.6658259389425\n",
      "Epoch: 3 Validation Loss:616.08242155479\n",
      "Epoch: 4 Training Loss:607.54251871533\n",
      "Epoch: 4 Validation Loss:614.6322837629458\n",
      "Epoch: 5 Training Loss:605.0212021414377\n",
      "Epoch: 5 Validation Loss:612.1767436178235\n",
      "Training with learning rate 1e-05 and weight decay 0.0001\n",
      "Epoch: 1 Training Loss:925.7709619017711\n",
      "Epoch: 1 Validation Loss:903.4554774503409\n",
      "Epoch: 2 Training Loss:810.8611613225688\n",
      "Epoch: 2 Validation Loss:705.9403917699461\n",
      "Epoch: 3 Training Loss:627.1373177274562\n",
      "Epoch: 3 Validation Loss:614.8176929866818\n",
      "Epoch: 4 Training Loss:605.1452569727992\n",
      "Epoch: 4 Validation Loss:612.7921796275192\n",
      "Epoch: 5 Training Loss:602.0867934830411\n",
      "Epoch: 5 Validation Loss:610.2553057240433\n",
      "Training with learning rate 1e-05 and weight decay 1e-05\n",
      "Epoch: 1 Training Loss:929.3264771497375\n",
      "Epoch: 1 Validation Loss:918.2194184579685\n",
      "Epoch: 2 Training Loss:853.9923587867105\n",
      "Epoch: 2 Validation Loss:781.9645771751477\n",
      "Epoch: 3 Training Loss:675.8883864409851\n",
      "Epoch: 3 Validation Loss:617.584296111182\n",
      "Epoch: 4 Training Loss:607.8511258439507\n",
      "Epoch: 4 Validation Loss:612.5067824975695\n",
      "Epoch: 5 Training Loss:604.8877752176963\n",
      "Epoch: 5 Validation Loss:610.7128144384423\n",
      "Best validation loss: 577.5069565629624\n",
      "Best hyperparameters: learning rate 0.001, weight decay 1e-05\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "weight_decays = [1e-3, 1e-4, 1e-5]\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_hyperparameters = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for wd in weight_decays:\n",
    "        print(f\"Training with learning rate {lr} and weight decay {wd}\")\n",
    "        model = MLP(train_set.shape[1],10).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        train(model, train_loader, val_loader, criterion, num_epochs) # use the training function you defined\n",
    "        val_loss = validate(model, val_loader, criterion) # you will need to define a validate function\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_hyperparameters = (lr, wd)\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss}\")\n",
    "print(f\"Best hyperparameters: learning rate {best_hyperparameters[0]}, weight decay {best_hyperparameters[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d0897cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss:2904.1357421875\n",
      "Epoch: 2 Loss:2864.908447265625\n",
      "Epoch: 3 Loss:2864.289306640625\n",
      "Epoch: 4 Loss:2863.82568359375\n",
      "Epoch: 5 Loss:2860.9482421875\n",
      "Epoch: 6 Loss:2864.11669921875\n",
      "Epoch: 7 Loss:2864.02490234375\n",
      "Epoch: 8 Loss:2862.87548828125\n",
      "Epoch: 9 Loss:2862.2080078125\n",
      "Epoch: 10 Loss:2857.65087890625\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader,criterion,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd7186ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb3ff3a4fd0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(torch.Tensor.cpu(torch.tensor(all_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95c4f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb8010a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_loss(model, test_set, test_label,criterion):\n",
    "    total_loss=0\n",
    "    test_dataset = TensorDataset(test_set, test_label)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y = torch.reshape(y,(-1,1))\n",
    "        output = model(x)\n",
    "        loss = torch.sqrt(criterion(output, y))#RMSE\n",
    "        total_loss += loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a27580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to see loss for validation set to tune the parameter. I didn't do that because linear regression is too simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df407cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2800.0242, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(view_loss(model, test_set, test_label,criterion)/test_set.shape[0]*320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24ae62ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([320, 14])\n"
     ]
    }
   ],
   "source": [
    "predict_input = torch.load('predict_input.pt').to(device)\n",
    "print(predict_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0398dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    predict_output = model(predict_input)\n",
    "    return predict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1963b248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[688.5222],\n",
      "        [688.4796],\n",
      "        [688.5222],\n",
      "        [688.4948],\n",
      "        [688.4459],\n",
      "        [784.9577],\n",
      "        [688.5222],\n",
      "        [784.9577],\n",
      "        [688.4985],\n",
      "        [688.5222],\n",
      "        [688.4368],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [688.5222],\n",
      "        [727.5194],\n",
      "        [688.5222],\n",
      "        [784.9577],\n",
      "        [784.9577],\n",
      "        [688.5222],\n",
      "        [688.3863],\n",
      "        [688.3274],\n",
      "        [688.5222],\n",
      "        [688.5222],\n",
      "        [688.3593],\n",
      "        [688.5222],\n",
      "        [688.5222],\n",
      "        [688.4796],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [784.9577],\n",
      "        [688.4542],\n",
      "        [688.5222],\n",
      "        [688.4938],\n",
      "        [688.4187],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [688.4985],\n",
      "        [688.4095],\n",
      "        [688.4854],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [688.4526],\n",
      "        [688.4368],\n",
      "        [688.3810],\n",
      "        [688.4630],\n",
      "        [688.4542],\n",
      "        [688.5222],\n",
      "        [688.5222],\n",
      "        [688.4586],\n",
      "        [688.4985],\n",
      "        [688.2800],\n",
      "        [727.5194],\n",
      "        [784.9577],\n",
      "        [688.5222],\n",
      "        [727.5194],\n",
      "        [727.5194],\n",
      "        [784.9577],\n",
      "        [688.4985],\n",
      "        [688.4985],\n",
      "        [688.5222],\n",
      "        [784.9577],\n",
      "        [727.5194],\n",
      "        [688.3810],\n",
      "        [720.4889],\n",
      "        [727.5194],\n",
      "        [688.5222],\n",
      "        [727.5194],\n",
      "        [666.7899],\n",
      "        [706.0730],\n",
      "        [667.0273],\n",
      "        [706.0730],\n",
      "        [706.0730],\n",
      "        [706.0730],\n",
      "        [763.5112],\n",
      "        [666.8868],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [666.8887],\n",
      "        [763.5112],\n",
      "        [706.0730],\n",
      "        [706.0730],\n",
      "        [666.8433],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [706.0730],\n",
      "        [706.0730],\n",
      "        [763.5112],\n",
      "        [659.9773],\n",
      "        [699.0425],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [706.0730],\n",
      "        [666.8887],\n",
      "        [666.8701],\n",
      "        [706.0730],\n",
      "        [667.0331],\n",
      "        [667.0331],\n",
      "        [763.5112],\n",
      "        [667.0142],\n",
      "        [666.9195],\n",
      "        [666.8701],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [666.8939],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [706.0730],\n",
      "        [666.8336],\n",
      "        [659.8896],\n",
      "        [706.0730],\n",
      "        [666.8992],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [667.0331],\n",
      "        [732.3929],\n",
      "        [706.0730],\n",
      "        [763.5112],\n",
      "        [706.0730],\n",
      "        [667.0331],\n",
      "        [667.0331],\n",
      "        [666.7899],\n",
      "        [699.0425],\n",
      "        [706.0730],\n",
      "        [706.0730],\n",
      "        [706.0730],\n",
      "        [667.0758],\n",
      "        [666.8336],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [706.0730],\n",
      "        [667.0331],\n",
      "        [763.5112],\n",
      "        [660.0452],\n",
      "        [763.5112],\n",
      "        [763.5112],\n",
      "        [666.8433],\n",
      "        [706.0730],\n",
      "        [666.8701],\n",
      "        [666.7802],\n",
      "        [763.5112],\n",
      "        [748.0595],\n",
      "        [690.6213],\n",
      "        [748.0595],\n",
      "        [690.6213],\n",
      "        [651.4368],\n",
      "        [651.5625],\n",
      "        [748.0595],\n",
      "        [651.5813],\n",
      "        [651.6240],\n",
      "        [748.0595],\n",
      "        [690.6213],\n",
      "        [748.0595],\n",
      "        [651.3819],\n",
      "        [748.0595],\n",
      "        [651.5561],\n",
      "        [683.5908],\n",
      "        [748.0595],\n",
      "        [690.6213],\n",
      "        [651.5477],\n",
      "        [651.3920],\n",
      "        [651.4292],\n",
      "        [690.6213],\n",
      "        [651.4828],\n",
      "        [651.5205],\n",
      "        [690.6213],\n",
      "        [651.6003],\n",
      "        [748.0595],\n",
      "        [748.0595],\n",
      "        [748.0595],\n",
      "        [651.4475],\n",
      "        [651.5965],\n",
      "        [748.0595],\n",
      "        [690.6213],\n",
      "        [651.5956],\n",
      "        [690.6213],\n",
      "        [748.0595],\n",
      "        [651.5604],\n",
      "        [651.5965],\n",
      "        [683.5908],\n",
      "        [748.0595],\n",
      "        [651.5545],\n",
      "        [748.0595],\n",
      "        [690.6213],\n",
      "        [651.5625],\n",
      "        [690.6213],\n",
      "        [690.6213],\n",
      "        [651.5545],\n",
      "        [683.5908],\n",
      "        [651.4475],\n",
      "        [618.6830],\n",
      "        [748.0595],\n",
      "        [651.3381],\n",
      "        [690.6213],\n",
      "        [690.6213],\n",
      "        [651.5828],\n",
      "        [651.5477],\n",
      "        [748.0595],\n",
      "        [748.0595],\n",
      "        [690.6213],\n",
      "        [651.5813],\n",
      "        [651.5965],\n",
      "        [690.6213],\n",
      "        [651.5649],\n",
      "        [651.4738],\n",
      "        [748.0595],\n",
      "        [644.4380],\n",
      "        [651.5104],\n",
      "        [651.4611],\n",
      "        [651.6240],\n",
      "        [683.5908],\n",
      "        [690.6213],\n",
      "        [741.0290],\n",
      "        [690.6213],\n",
      "        [651.6003],\n",
      "        [651.4249],\n",
      "        [690.6213],\n",
      "        [748.0595],\n",
      "        [610.3687],\n",
      "        [649.4085],\n",
      "        [610.3687],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [610.2701],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [610.3026],\n",
      "        [706.8468],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [610.3687],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [610.3628],\n",
      "        [610.3522],\n",
      "        [649.4085],\n",
      "        [706.8468],\n",
      "        [649.4085],\n",
      "        [610.3628],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [610.3628],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [610.3077],\n",
      "        [649.4085],\n",
      "        [610.3477],\n",
      "        [610.3628],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [642.3779],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [610.3628],\n",
      "        [649.4085],\n",
      "        [706.8468],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [649.4085],\n",
      "        [677.1222],\n",
      "        [707.6376],\n",
      "        [779.1368],\n",
      "        [721.6987],\n",
      "        [779.1368],\n",
      "        [677.0975],\n",
      "        [779.1368],\n",
      "        [677.1674],\n",
      "        [721.6987],\n",
      "        [721.6987],\n",
      "        [700.6071],\n",
      "        [714.6682],\n",
      "        [779.1368],\n",
      "        [700.6071],\n",
      "        [779.1368],\n",
      "        [779.1368],\n",
      "        [779.1368],\n",
      "        [779.1368],\n",
      "        [721.6987],\n",
      "        [779.1368],\n",
      "        [677.2541],\n",
      "        [779.1368],\n",
      "        [765.0759],\n",
      "        [714.6682],\n",
      "        [721.6987],\n",
      "        [779.1368],\n",
      "        [677.1674],\n",
      "        [721.6987],\n",
      "        [779.1368],\n",
      "        [779.1368]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = predict(model)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef0f06b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>688.522156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>688.479553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>688.522156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>688.494751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>688.445862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TRIP_ID  TRAVEL_TIME\n",
       "0      T1   688.522156\n",
       "1      T2   688.479553\n",
       "2      T3   688.522156\n",
       "3      T4   688.494751\n",
       "4      T5   688.445862"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_predict = pd.read_csv('test_public.csv')\n",
    "linear_predict = linear_predict['TRIP_ID']\n",
    "predict_tensor = out.to('cpu').detach().numpy().flatten()\n",
    "linear_predict= pd.concat([linear_predict, pd.DataFrame(predict_tensor)], axis=1)\n",
    "linear_predict = linear_predict.rename(columns={0: 'TRAVEL_TIME'})\n",
    "linear_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ca794bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predict.to_csv('linear_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8f5d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'linear.pth'\n",
    "torch.save(model.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87df52b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MLP:\n\tsize mismatch for layer1.0.weight: copying a param with shape torch.Size([10, 14]) from checkpoint, the shape in current model is torch.Size([20, 14]).\n\tsize mismatch for layer1.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for layer2.0.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for layer2.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for output_layer.weight: copying a param with shape torch.Size([1, 10]) from checkpoint, the shape in current model is torch.Size([1, 20]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_127/1768665163.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MLP:\n\tsize mismatch for layer1.0.weight: copying a param with shape torch.Size([10, 14]) from checkpoint, the shape in current model is torch.Size([20, 14]).\n\tsize mismatch for layer1.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for layer2.0.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([20, 20]).\n\tsize mismatch for layer2.0.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([20]).\n\tsize mismatch for output_layer.weight: copying a param with shape torch.Size([1, 10]) from checkpoint, the shape in current model is torch.Size([1, 20])."
     ]
    }
   ],
   "source": [
    "model = MLP(14,20).to(device)\n",
    "model_state = torch.load('linear.pth')\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8519fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sklearn for something like gradient boosting or random forest\n",
    "\n",
    "#Model Selection: Gradient Boosting,Random Forest,Extra Randomized Trees, SVM, Linear Regression, Logistic Regression, Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: build other models\n",
    "#TODO: report loss on validation sets and tune parameters for each model\n",
    "#TODO: run on test sets and report test loss\n",
    "#TODO: predict travel time(test_features) and submit to kaggle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
