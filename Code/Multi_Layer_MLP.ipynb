{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7608cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821145ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218a9ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=torch.load('train_features.pt')\n",
    "train_labels=torch.load('train_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ee4cc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1704759, 14])\n",
      "torch.Size([1704759])\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a08105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1704759, 15])\n"
     ]
    }
   ],
   "source": [
    "train = torch.cat([train_features, train_labels.reshape(-1,1)],1)\n",
    "print(train.shape)\n",
    "train = train[torch.randperm(train.size(0))] #shuffling dataset, parameter down need to be updated\n",
    "train_set = train[0:1500000,                            0:train.shape[1]-1]\n",
    "train_label = train[0:1500000,                          train.shape[1]-1]\n",
    "validation_set = train[1500000:1600000,                 0:train.shape[1]-1]\n",
    "validation_label = train[1500000:1600000,               train.shape[1]-1]\n",
    "test_set = train[1600000:train.shape[0],                0:train.shape[1]-1]\n",
    "test_label = train[1600000:train.shape[0],              train.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cd9c67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000, 11.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        [ 0.4963,  1.9732,  3.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  2.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [-1.0353,  1.3840,  3.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, 10.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  5.0000,  ...,  0.0000,  1.0000,  0.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a60831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([104759, 14])\n"
     ]
    }
   ],
   "source": [
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd80065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may save them if you want\n",
    "torch.save(train_set,'train_set.pt')\n",
    "torch.save(train_label,'train_label.pt')\n",
    "torch.save(validation_set,'validation_set.pt')\n",
    "torch.save(validation_label,'validation_label.pt')\n",
    "torch.save(test_set,'test_set.pt')\n",
    "torch.save(test_label,'test_label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622b7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_features\n",
    "del train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00a557eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(train_set.dtype)\n",
    "print(train_label.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76360068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1500000, 14])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61624c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c56a75fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c3fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output_layer = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b37a8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output_layer = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3450c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features in your data and the size of the hidden layer\n",
    "input_features = train_set.shape[1]\n",
    "hidden_size = 10\n",
    "\n",
    "# Initialize the model and move to the device\n",
    "model = MLP(input_features, hidden_size)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545717a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2ed2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y) + self.eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b8b993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "learning_rate = 0.0001\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 60\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "147bce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11719\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(train_set, train_label)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(validation_set, validation_label)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "print(len(train_loader))\n",
    "all_losses = []\n",
    "train_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c422f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():  # We don't need gradients for validation\n",
    "        for inputs, targets in val_loader:\n",
    "            # Move data to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Reshape targets\n",
    "            targets = torch.reshape(targets,(-1,1))\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = torch.sqrt(criterion(outputs, targets))  # RMSE\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "    # Return average loss\n",
    "    average_val_loss = running_val_loss / len(val_loader)\n",
    "    return average_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79e8f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        group_320_loss = 0\n",
    "        for i,(x, y) in enumerate(train_loader,0):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y = torch.reshape(y,(-1,1))\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = torch.sqrt(criterion(output, y))#RMSE\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            group_320_loss += loss.item()\n",
    "        all_losses.append(epoch_loss/len(train_loader))\n",
    "        print(f\"Epoch: {epoch+1} Training Loss:{epoch_loss/len(train_loader)}\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val = x_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                y_val = torch.reshape(y_val,(-1,1))\n",
    "                preds = model(x_val)\n",
    "                val_loss += torch.sqrt(criterion(preds, y_val)).item() # RMSE\n",
    "        print(f\"Epoch: {epoch+1} Validation Loss:{val_loss/len(val_loader)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95eb189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with learning rate 0.001 and weight decay 0.001\n",
      "Epoch: 1 Training Loss:583.0806999795723\n",
      "Epoch: 1 Validation Loss:566.7689950836826\n",
      "Epoch: 2 Training Loss:574.1835774567278\n",
      "Epoch: 2 Validation Loss:564.5013587741767\n",
      "Epoch: 3 Training Loss:573.2573976904899\n",
      "Epoch: 3 Validation Loss:566.017265920218\n",
      "Epoch: 4 Training Loss:573.430598250753\n",
      "Epoch: 4 Validation Loss:567.0644404727987\n",
      "Epoch: 5 Training Loss:573.5424430991045\n",
      "Epoch: 5 Validation Loss:563.7239495275575\n",
      "Training with learning rate 0.001 and weight decay 0.001\n",
      "Epoch: 1 Training Loss:578.8068972920505\n",
      "Epoch: 1 Validation Loss:566.2679922112424\n",
      "Epoch: 2 Training Loss:573.2519973395515\n",
      "Epoch: 2 Validation Loss:564.0583711259272\n",
      "Epoch: 3 Training Loss:572.6715437486032\n",
      "Epoch: 3 Validation Loss:565.0921165969078\n",
      "Epoch: 4 Training Loss:572.6074808157999\n",
      "Epoch: 4 Validation Loss:565.458114848561\n",
      "Epoch: 5 Training Loss:572.8957098485545\n",
      "Epoch: 5 Validation Loss:563.8831811906127\n",
      "Training with learning rate 0.001 and weight decay 0.001\n",
      "Epoch: 1 Training Loss:578.1075609761991\n",
      "Epoch: 1 Validation Loss:564.6546722041135\n",
      "Epoch: 2 Training Loss:573.0287947561545\n",
      "Epoch: 2 Validation Loss:563.9373174607563\n",
      "Epoch: 3 Training Loss:572.6823041818077\n",
      "Epoch: 3 Validation Loss:564.4847415819125\n",
      "Epoch: 4 Training Loss:571.8106128944249\n",
      "Epoch: 4 Validation Loss:565.0571532344024\n",
      "Epoch: 5 Training Loss:571.103856089742\n",
      "Epoch: 5 Validation Loss:563.9928444967923\n",
      "Training with learning rate 0.001 and weight decay 0.0001\n",
      "Epoch: 1 Training Loss:582.6735774630298\n",
      "Epoch: 1 Validation Loss:565.9924586437028\n",
      "Epoch: 2 Training Loss:573.2794421739836\n",
      "Epoch: 2 Validation Loss:562.7795813152292\n",
      "Epoch: 3 Training Loss:572.5953851701945\n",
      "Epoch: 3 Validation Loss:563.9122856662431\n",
      "Epoch: 4 Training Loss:572.7239607364938\n",
      "Epoch: 4 Validation Loss:565.2597149576198\n",
      "Epoch: 5 Training Loss:572.6045671168911\n",
      "Epoch: 5 Validation Loss:564.940020384883\n",
      "Training with learning rate 0.001 and weight decay 0.0001\n",
      "Epoch: 1 Training Loss:578.8792125631268\n",
      "Epoch: 1 Validation Loss:564.9678851986115\n",
      "Epoch: 2 Training Loss:573.4154114861956\n",
      "Epoch: 2 Validation Loss:565.1868900389376\n",
      "Epoch: 3 Training Loss:573.3058709050925\n",
      "Epoch: 3 Validation Loss:563.4526027452465\n",
      "Epoch: 4 Training Loss:572.6565756382354\n",
      "Epoch: 4 Validation Loss:564.0654850018307\n",
      "Epoch: 5 Training Loss:573.1522415933251\n",
      "Epoch: 5 Validation Loss:563.1858200297779\n",
      "Training with learning rate 0.001 and weight decay 0.0001\n",
      "Epoch: 1 Training Loss:578.5045246111573\n",
      "Epoch: 1 Validation Loss:564.977001656345\n",
      "Epoch: 2 Training Loss:573.5662475678383\n",
      "Epoch: 2 Validation Loss:565.5609320544769\n",
      "Epoch: 3 Training Loss:572.9113700060076\n",
      "Epoch: 3 Validation Loss:565.2221854338643\n",
      "Epoch: 4 Training Loss:572.2675311852462\n",
      "Epoch: 4 Validation Loss:565.0778014121419\n",
      "Epoch: 5 Training Loss:571.9282237245866\n",
      "Epoch: 5 Validation Loss:563.3812165458615\n",
      "Training with learning rate 0.001 and weight decay 1e-05\n",
      "Epoch: 1 Training Loss:583.2149773806127\n",
      "Epoch: 1 Validation Loss:567.3711047425761\n",
      "Epoch: 2 Training Loss:573.4929777891301\n",
      "Epoch: 2 Validation Loss:563.593448162994\n",
      "Epoch: 3 Training Loss:572.9147264357058\n",
      "Epoch: 3 Validation Loss:566.2820886378859\n",
      "Epoch: 4 Training Loss:572.9053742524065\n",
      "Epoch: 4 Validation Loss:564.7414794843775\n",
      "Epoch: 5 Training Loss:572.2969495088272\n",
      "Epoch: 5 Validation Loss:563.8029266474572\n",
      "Training with learning rate 0.001 and weight decay 1e-05\n",
      "Epoch: 1 Training Loss:579.4086074392912\n",
      "Epoch: 1 Validation Loss:566.6482185856776\n",
      "Epoch: 2 Training Loss:573.5425124185892\n",
      "Epoch: 2 Validation Loss:564.1985768265092\n",
      "Epoch: 3 Training Loss:572.9548435323484\n",
      "Epoch: 3 Validation Loss:565.051103373483\n",
      "Epoch: 4 Training Loss:571.7673974706508\n",
      "Epoch: 4 Validation Loss:565.9456473537842\n",
      "Epoch: 5 Training Loss:572.3313157919558\n",
      "Epoch: 5 Validation Loss:564.1666737151924\n",
      "Training with learning rate 0.001 and weight decay 1e-05\n",
      "Epoch: 1 Training Loss:577.8529741105107\n",
      "Epoch: 1 Validation Loss:565.031343007347\n",
      "Epoch: 2 Training Loss:572.494814992775\n",
      "Epoch: 2 Validation Loss:564.339658789656\n",
      "Epoch: 3 Training Loss:572.1516233376344\n",
      "Epoch: 3 Validation Loss:563.1854977696199\n",
      "Epoch: 4 Training Loss:571.7478438578466\n",
      "Epoch: 4 Validation Loss:564.1514500125585\n",
      "Epoch: 5 Training Loss:571.8323301016974\n",
      "Epoch: 5 Validation Loss:563.8718719189546\n",
      "Training with learning rate 0.0001 and weight decay 0.001\n",
      "Epoch: 1 Training Loss:649.2489149150756\n",
      "Epoch: 1 Validation Loss:588.3792551617857\n",
      "Epoch: 2 Training Loss:586.3641334199714\n",
      "Epoch: 2 Validation Loss:571.9598999804438\n",
      "Epoch: 3 Training Loss:576.5614285879609\n",
      "Epoch: 3 Validation Loss:565.7865588480437\n",
      "Epoch: 4 Training Loss:575.0923686928793\n",
      "Epoch: 4 Validation Loss:565.4750282058179\n",
      "Epoch: 5 Training Loss:575.0531549382936\n",
      "Epoch: 5 Validation Loss:568.2934264746219\n",
      "Training with learning rate 0.0001 and weight decay 0.001\n",
      "Epoch: 1 Training Loss:623.1243116683303\n",
      "Epoch: 1 Validation Loss:574.3099655180655\n",
      "Epoch: 2 Training Loss:576.9398663642311\n",
      "Epoch: 2 Validation Loss:567.8264486028534\n",
      "Epoch: 3 Training Loss:575.0610112114483\n",
      "Epoch: 3 Validation Loss:566.1186206351467\n",
      "Epoch: 4 Training Loss:574.4738284658781\n",
      "Epoch: 4 Validation Loss:567.8330083982501\n",
      "Epoch: 5 Training Loss:574.3620213244045\n",
      "Epoch: 5 Validation Loss:566.2144154495561\n",
      "Training with learning rate 0.0001 and weight decay 0.001\n",
      "Epoch: 1 Training Loss:610.0033922284138\n",
      "Epoch: 1 Validation Loss:569.219082139809\n",
      "Epoch: 2 Training Loss:575.8235563969426\n",
      "Epoch: 2 Validation Loss:566.204374912528\n",
      "Epoch: 3 Training Loss:574.2921252751556\n",
      "Epoch: 3 Validation Loss:567.1959166426119\n",
      "Epoch: 4 Training Loss:574.3234278170034\n",
      "Epoch: 4 Validation Loss:565.6531457199321\n",
      "Epoch: 5 Training Loss:574.5419931770622\n",
      "Epoch: 5 Validation Loss:564.5588631755026\n",
      "Training with learning rate 0.0001 and weight decay 0.0001\n",
      "Epoch: 1 Training Loss:648.7502820825239\n",
      "Epoch: 1 Validation Loss:582.9338240083486\n",
      "Epoch: 2 Training Loss:582.5772053855038\n",
      "Epoch: 2 Validation Loss:568.2252627401419\n",
      "Epoch: 3 Training Loss:575.6734560854107\n",
      "Epoch: 3 Validation Loss:566.3452527417788\n",
      "Epoch: 4 Training Loss:575.3030784470869\n",
      "Epoch: 4 Validation Loss:565.8320713738791\n",
      "Epoch: 5 Training Loss:574.4753140155666\n",
      "Epoch: 5 Validation Loss:564.3000670449519\n",
      "Training with learning rate 0.0001 and weight decay 0.0001\n",
      "Epoch: 1 Training Loss:621.0121074825925\n",
      "Epoch: 1 Validation Loss:574.1171510468213\n",
      "Epoch: 2 Training Loss:577.477423050652\n",
      "Epoch: 2 Validation Loss:565.2938070950108\n",
      "Epoch: 3 Training Loss:575.3665226886618\n",
      "Epoch: 3 Validation Loss:567.9742315857363\n",
      "Epoch: 4 Training Loss:574.6401729328212\n",
      "Epoch: 4 Validation Loss:566.4808569656147\n",
      "Epoch: 5 Training Loss:574.6354493076803\n",
      "Epoch: 5 Validation Loss:565.316249581384\n",
      "Training with learning rate 0.0001 and weight decay 0.0001\n",
      "Epoch: 1 Training Loss:618.7450717809166\n",
      "Epoch: 1 Validation Loss:572.4026344968048\n",
      "Epoch: 2 Training Loss:576.3915762095253\n",
      "Epoch: 2 Validation Loss:567.29130881243\n",
      "Epoch: 3 Training Loss:574.6311213908947\n",
      "Epoch: 3 Validation Loss:567.2090315181173\n",
      "Epoch: 4 Training Loss:574.9902556714206\n",
      "Epoch: 4 Validation Loss:566.3527217384187\n",
      "Epoch: 5 Training Loss:573.9935419007936\n",
      "Epoch: 5 Validation Loss:566.8578832117472\n",
      "Training with learning rate 0.0001 and weight decay 1e-05\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "weight_decays = [1e-3, 1e-4, 1e-5]\n",
    "hidden_sizes = [10,20,30]\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_hyperparameters = None\n",
    "best_hidden_sizes = 10\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for wd in weight_decays:\n",
    "        for hs in hidden_sizes:\n",
    "            print(f\"Training with learning rate {lr} and weight decay {wd} and hidden size {hs}\")\n",
    "            model = MLP(train_set.shape[1],hs).to(device)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            train(model, train_loader, val_loader, criterion, num_epochs) # use the training function you defined\n",
    "            val_loss = validate(model, val_loader, criterion) # you will need to define a validate function\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_hyperparameters = (lr, wd,hs)\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss}\")\n",
    "print(f\"Best hyperparameters: learning rate {best_hyperparameters[0]}, weight decay {best_hyperparameters[1]}, weight decay {best_hyperparameters[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb84deae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d0897cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Loss:609.7405943256543\n",
      "Epoch: 1 Validation Loss:602.8787796918084\n",
      "Epoch: 2 Training Loss:600.6609992424328\n",
      "Epoch: 2 Validation Loss:600.3429184155086\n",
      "Epoch: 3 Training Loss:600.1730779951695\n",
      "Epoch: 3 Validation Loss:600.0911054684378\n",
      "Epoch: 4 Training Loss:599.20798015684\n",
      "Epoch: 4 Validation Loss:600.6726559299947\n",
      "Epoch: 5 Training Loss:599.9125004057205\n",
      "Epoch: 5 Validation Loss:603.0949666445213\n",
      "Epoch: 6 Training Loss:599.5090559265985\n",
      "Epoch: 6 Validation Loss:600.3225181950328\n",
      "Epoch: 7 Training Loss:599.1851631592276\n",
      "Epoch: 7 Validation Loss:602.6141812063544\n",
      "Epoch: 8 Training Loss:599.7139676358779\n",
      "Epoch: 8 Validation Loss:601.3491472405241\n",
      "Epoch: 9 Training Loss:598.9564692411562\n",
      "Epoch: 9 Validation Loss:599.2540269934613\n",
      "Epoch: 10 Training Loss:598.8608417317306\n",
      "Epoch: 10 Validation Loss:598.7346404873197\n",
      "Epoch: 11 Training Loss:599.0900915520052\n",
      "Epoch: 11 Validation Loss:599.5697535053848\n",
      "Epoch: 12 Training Loss:598.9871480736535\n",
      "Epoch: 12 Validation Loss:601.1447088529387\n",
      "Epoch: 13 Training Loss:598.7240004296575\n",
      "Epoch: 13 Validation Loss:600.1025254037374\n",
      "Epoch: 14 Training Loss:598.8111403076526\n",
      "Epoch: 14 Validation Loss:598.3646960246289\n",
      "Epoch: 15 Training Loss:598.7837051507485\n",
      "Epoch: 15 Validation Loss:599.6075406281844\n",
      "Epoch: 16 Training Loss:598.0660102506355\n",
      "Epoch: 16 Validation Loss:599.462442383437\n",
      "Epoch: 17 Training Loss:598.0637512832018\n",
      "Epoch: 17 Validation Loss:599.1273445070857\n",
      "Epoch: 18 Training Loss:599.1922823484974\n",
      "Epoch: 18 Validation Loss:600.6208247504271\n",
      "Epoch: 19 Training Loss:598.506848476295\n",
      "Epoch: 19 Validation Loss:601.9356905651824\n",
      "Epoch: 20 Training Loss:598.3507641185946\n",
      "Epoch: 20 Validation Loss:599.5217791310967\n",
      "Epoch: 21 Training Loss:598.0234322813614\n",
      "Epoch: 21 Validation Loss:600.2146918255349\n",
      "Epoch: 22 Training Loss:597.5032591179721\n",
      "Epoch: 22 Validation Loss:601.4689582375919\n",
      "Epoch: 23 Training Loss:597.895192423395\n",
      "Epoch: 23 Validation Loss:599.9050907222816\n",
      "Epoch: 24 Training Loss:597.7268446606472\n",
      "Epoch: 24 Validation Loss:598.5001454853341\n",
      "Epoch: 25 Training Loss:597.7415114571306\n",
      "Epoch: 25 Validation Loss:598.8389553060313\n",
      "Epoch: 26 Training Loss:597.807697787343\n",
      "Epoch: 26 Validation Loss:598.5721196323404\n",
      "Epoch: 27 Training Loss:597.128204249351\n",
      "Epoch: 27 Validation Loss:596.2120240740763\n",
      "Epoch: 28 Training Loss:597.7798612353562\n",
      "Epoch: 28 Validation Loss:598.2530348209469\n",
      "Epoch: 29 Training Loss:597.113323717844\n",
      "Epoch: 29 Validation Loss:595.6443941550486\n",
      "Epoch: 30 Training Loss:597.3564223129906\n",
      "Epoch: 30 Validation Loss:598.8405255173783\n",
      "Epoch: 31 Training Loss:596.9847436275526\n",
      "Epoch: 31 Validation Loss:597.5082182042739\n",
      "Epoch: 32 Training Loss:597.3552857408833\n",
      "Epoch: 32 Validation Loss:597.6938430512957\n",
      "Epoch: 33 Training Loss:597.0750993327767\n",
      "Epoch: 33 Validation Loss:598.7175244577705\n",
      "Epoch: 34 Training Loss:596.5826430390318\n",
      "Epoch: 34 Validation Loss:600.5078372418728\n",
      "Epoch: 35 Training Loss:596.8697755541632\n",
      "Epoch: 35 Validation Loss:598.4120232077206\n",
      "Epoch: 36 Training Loss:597.0177174840062\n",
      "Epoch: 36 Validation Loss:598.6353918597522\n",
      "Epoch: 37 Training Loss:596.562933930847\n",
      "Epoch: 37 Validation Loss:597.6289525727177\n",
      "Epoch: 38 Training Loss:596.0857782533973\n",
      "Epoch: 38 Validation Loss:597.6266084168573\n",
      "Epoch: 39 Training Loss:596.6373431845954\n",
      "Epoch: 39 Validation Loss:599.1922896207141\n",
      "Epoch: 40 Training Loss:596.8307752325242\n",
      "Epoch: 40 Validation Loss:597.4585986125195\n",
      "Epoch: 41 Training Loss:596.0451885411861\n",
      "Epoch: 41 Validation Loss:598.8907073038008\n",
      "Epoch: 42 Training Loss:596.2957892158718\n",
      "Epoch: 42 Validation Loss:599.8806287760625\n",
      "Epoch: 43 Training Loss:596.5270862060152\n",
      "Epoch: 43 Validation Loss:597.5394767897818\n",
      "Epoch: 44 Training Loss:596.8658961317159\n",
      "Epoch: 44 Validation Loss:600.8446274389087\n",
      "Epoch: 45 Training Loss:596.8242022920177\n",
      "Epoch: 45 Validation Loss:597.5587828262993\n",
      "Epoch: 46 Training Loss:596.4042603419252\n",
      "Epoch: 46 Validation Loss:597.9784242283657\n",
      "Epoch: 47 Training Loss:597.0032232697786\n",
      "Epoch: 47 Validation Loss:597.536814228653\n",
      "Epoch: 48 Training Loss:596.4778977631811\n",
      "Epoch: 48 Validation Loss:597.6062474945927\n",
      "Epoch: 49 Training Loss:597.5191989602139\n",
      "Epoch: 49 Validation Loss:594.6122148128421\n",
      "Epoch: 50 Training Loss:596.0848574292916\n",
      "Epoch: 50 Validation Loss:595.5789931899751\n",
      "Epoch: 51 Training Loss:596.743023185297\n",
      "Epoch: 51 Validation Loss:598.8493692929787\n",
      "Epoch: 52 Training Loss:596.3935892414504\n",
      "Epoch: 52 Validation Loss:598.0699895678274\n",
      "Epoch: 53 Training Loss:596.5713515611667\n",
      "Epoch: 53 Validation Loss:597.5961409078535\n",
      "Epoch: 54 Training Loss:595.745465435279\n",
      "Epoch: 54 Validation Loss:595.6515054532024\n",
      "Epoch: 55 Training Loss:596.0905615185418\n",
      "Epoch: 55 Validation Loss:597.1937042002178\n",
      "Epoch: 56 Training Loss:596.122704603656\n",
      "Epoch: 56 Validation Loss:598.2194508115958\n",
      "Epoch: 57 Training Loss:596.3419080653363\n",
      "Epoch: 57 Validation Loss:598.1817060309603\n",
      "Epoch: 58 Training Loss:596.2742739691345\n",
      "Epoch: 58 Validation Loss:598.0482924283313\n",
      "Epoch: 59 Training Loss:596.4848032981546\n",
      "Epoch: 59 Validation Loss:597.8133642874715\n",
      "Epoch: 60 Training Loss:596.8464886342841\n",
      "Epoch: 60 Validation Loss:597.5357225813219\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MLP(train_set.shape[1],10).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "train(model, train_loader, val_loader, criterion, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd7186ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe1ee953280>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(torch.Tensor.cpu(torch.tensor(all_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "caf62d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe1eb63e910>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(torch.Tensor.cpu(torch.tensor(all_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95c4f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb8010a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_loss(model, test_set, test_label,criterion):\n",
    "    total_loss=0\n",
    "    test_dataset = TensorDataset(test_set, test_label)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y = torch.reshape(y,(-1,1))\n",
    "        output = model(x)\n",
    "        loss = torch.sqrt(criterion(output, y))#RMSE\n",
    "        total_loss += loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a27580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to see loss for validation set to tune the parameter. I didn't do that because linear regression is too simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df407cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2800.0242, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(view_loss(model, test_set, test_label,criterion)/test_set.shape[0]*320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24ae62ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([320, 14])\n"
     ]
    }
   ],
   "source": [
    "predict_input = torch.load('predict_input.pt').to(device)\n",
    "print(predict_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0398dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    predict_output = model(predict_input)\n",
    "    return predict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1963b248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[907.8166],\n",
      "        [834.1433],\n",
      "        [907.8166],\n",
      "        [853.2374],\n",
      "        [828.6076],\n",
      "        [892.8090],\n",
      "        [907.8166],\n",
      "        [892.8090],\n",
      "        [837.2757],\n",
      "        [907.8166],\n",
      "        [728.0526],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [907.8166],\n",
      "        [949.9908],\n",
      "        [907.8166],\n",
      "        [892.8090],\n",
      "        [892.8090],\n",
      "        [907.8166],\n",
      "        [809.0719],\n",
      "        [880.5782],\n",
      "        [907.8166],\n",
      "        [907.8166],\n",
      "        [786.9183],\n",
      "        [907.8166],\n",
      "        [907.8166],\n",
      "        [834.1433],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [892.8090],\n",
      "        [812.8345],\n",
      "        [907.8166],\n",
      "        [856.8908],\n",
      "        [772.9594],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [837.2757],\n",
      "        [819.7927],\n",
      "        [815.0016],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [684.4656],\n",
      "        [728.0526],\n",
      "        [800.4088],\n",
      "        [812.9415],\n",
      "        [812.8345],\n",
      "        [907.8166],\n",
      "        [907.8166],\n",
      "        [818.9462],\n",
      "        [837.2757],\n",
      "        [775.3945],\n",
      "        [949.9908],\n",
      "        [892.8090],\n",
      "        [907.8166],\n",
      "        [949.9908],\n",
      "        [949.9908],\n",
      "        [892.8090],\n",
      "        [837.2757],\n",
      "        [837.2757],\n",
      "        [907.8166],\n",
      "        [892.8090],\n",
      "        [949.9908],\n",
      "        [800.4088],\n",
      "        [955.7184],\n",
      "        [949.9908],\n",
      "        [907.8166],\n",
      "        [949.9908],\n",
      "        [648.9785],\n",
      "        [961.7955],\n",
      "        [655.6952],\n",
      "        [961.7955],\n",
      "        [961.7955],\n",
      "        [961.7955],\n",
      "        [771.5186],\n",
      "        [674.9833],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [681.2866],\n",
      "        [771.5186],\n",
      "        [961.7955],\n",
      "        [961.7955],\n",
      "        [619.8658],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [961.7955],\n",
      "        [961.7955],\n",
      "        [771.5186],\n",
      "        [617.3055],\n",
      "        [959.3467],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [961.7955],\n",
      "        [681.2866],\n",
      "        [771.8055],\n",
      "        [961.7955],\n",
      "        [652.1252],\n",
      "        [652.1252],\n",
      "        [771.5186],\n",
      "        [666.1979],\n",
      "        [586.0095],\n",
      "        [771.8055],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [632.7906],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [961.7955],\n",
      "        [663.1586],\n",
      "        [701.7570],\n",
      "        [961.7955],\n",
      "        [731.7718],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [652.1252],\n",
      "        [789.7946],\n",
      "        [961.7955],\n",
      "        [771.5186],\n",
      "        [961.7955],\n",
      "        [652.1252],\n",
      "        [652.1252],\n",
      "        [648.9785],\n",
      "        [959.3467],\n",
      "        [961.7955],\n",
      "        [961.7955],\n",
      "        [961.7955],\n",
      "        [831.7287],\n",
      "        [663.1586],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [961.7955],\n",
      "        [652.1252],\n",
      "        [771.5186],\n",
      "        [808.9216],\n",
      "        [771.5186],\n",
      "        [771.5186],\n",
      "        [619.8658],\n",
      "        [961.7955],\n",
      "        [771.8055],\n",
      "        [695.3958],\n",
      "        [771.5186],\n",
      "        [899.7529],\n",
      "        [943.3320],\n",
      "        [899.7529],\n",
      "        [943.3320],\n",
      "        [782.3563],\n",
      "        [842.3588],\n",
      "        [899.7529],\n",
      "        [841.0872],\n",
      "        [913.2590],\n",
      "        [899.7529],\n",
      "        [943.3320],\n",
      "        [899.7529],\n",
      "        [782.4011],\n",
      "        [899.7529],\n",
      "        [819.7783],\n",
      "        [949.0596],\n",
      "        [899.7529],\n",
      "        [943.3320],\n",
      "        [835.5515],\n",
      "        [878.7991],\n",
      "        [888.3044],\n",
      "        [943.3320],\n",
      "        [807.4153],\n",
      "        [783.7586],\n",
      "        [943.3320],\n",
      "        [844.2196],\n",
      "        [899.7529],\n",
      "        [899.7529],\n",
      "        [899.7529],\n",
      "        [829.8873],\n",
      "        [860.1811],\n",
      "        [899.7529],\n",
      "        [943.3320],\n",
      "        [863.8346],\n",
      "        [943.3320],\n",
      "        [899.7529],\n",
      "        [825.8900],\n",
      "        [860.1811],\n",
      "        [949.0596],\n",
      "        [899.7529],\n",
      "        [689.3669],\n",
      "        [899.7529],\n",
      "        [943.3320],\n",
      "        [842.3588],\n",
      "        [943.3320],\n",
      "        [943.3320],\n",
      "        [689.3669],\n",
      "        [949.0596],\n",
      "        [829.8873],\n",
      "        [895.8181],\n",
      "        [899.7529],\n",
      "        [768.9484],\n",
      "        [943.3320],\n",
      "        [943.3320],\n",
      "        [683.7782],\n",
      "        [835.5515],\n",
      "        [899.7529],\n",
      "        [899.7529],\n",
      "        [943.3320],\n",
      "        [841.0872],\n",
      "        [860.1811],\n",
      "        [943.3320],\n",
      "        [819.8853],\n",
      "        [805.2316],\n",
      "        [899.7529],\n",
      "        [785.1594],\n",
      "        [783.8131],\n",
      "        [793.9248],\n",
      "        [913.2590],\n",
      "        [949.0596],\n",
      "        [943.3320],\n",
      "        [876.7366],\n",
      "        [943.3320],\n",
      "        [844.2196],\n",
      "        [829.4293],\n",
      "        [943.3320],\n",
      "        [899.7529],\n",
      "        [567.2177],\n",
      "        [596.1625],\n",
      "        [567.2177],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [520.8994],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [494.6404],\n",
      "        [677.2890],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [567.2177],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [566.3666],\n",
      "        [543.9189],\n",
      "        [596.1625],\n",
      "        [677.2890],\n",
      "        [596.1625],\n",
      "        [566.3666],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [566.3666],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [498.4897],\n",
      "        [596.1625],\n",
      "        [549.4933],\n",
      "        [566.3666],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [598.7366],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [566.3666],\n",
      "        [596.1625],\n",
      "        [677.2890],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [596.1625],\n",
      "        [686.4007],\n",
      "        [895.0610],\n",
      "        [790.3519],\n",
      "        [883.0340],\n",
      "        [790.3519],\n",
      "        [686.3777],\n",
      "        [790.3519],\n",
      "        [769.1398],\n",
      "        [883.0340],\n",
      "        [883.0340],\n",
      "        [889.2631],\n",
      "        [890.1978],\n",
      "        [790.3519],\n",
      "        [889.2631],\n",
      "        [790.3519],\n",
      "        [790.3519],\n",
      "        [790.3519],\n",
      "        [790.3519],\n",
      "        [883.0340],\n",
      "        [790.3519],\n",
      "        [786.7552],\n",
      "        [790.3519],\n",
      "        [770.3776],\n",
      "        [890.1978],\n",
      "        [883.0340],\n",
      "        [790.3519],\n",
      "        [769.1398],\n",
      "        [883.0340],\n",
      "        [790.3519],\n",
      "        [790.3519]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = predict(model)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec6d1d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 915.4891],\n",
      "        [ 820.9103],\n",
      "        [ 915.4891],\n",
      "        [ 854.3281],\n",
      "        [ 817.9877],\n",
      "        [ 906.7170],\n",
      "        [ 915.4891],\n",
      "        [ 906.7170],\n",
      "        [ 876.6290],\n",
      "        [ 915.4891],\n",
      "        [ 715.3895],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 915.4891],\n",
      "        [ 928.2835],\n",
      "        [ 915.4891],\n",
      "        [ 906.7170],\n",
      "        [ 906.7170],\n",
      "        [ 915.4891],\n",
      "        [ 806.2587],\n",
      "        [ 786.5085],\n",
      "        [ 915.4891],\n",
      "        [ 915.4891],\n",
      "        [ 797.7747],\n",
      "        [ 915.4891],\n",
      "        [ 915.4891],\n",
      "        [ 820.9103],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 906.7170],\n",
      "        [ 808.2930],\n",
      "        [ 915.4891],\n",
      "        [ 848.8781],\n",
      "        [ 783.6944],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 876.6290],\n",
      "        [ 810.4292],\n",
      "        [ 840.0967],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 660.4532],\n",
      "        [ 715.3895],\n",
      "        [ 805.6210],\n",
      "        [ 807.5388],\n",
      "        [ 808.2930],\n",
      "        [ 915.4891],\n",
      "        [ 915.4891],\n",
      "        [ 812.1661],\n",
      "        [ 876.6290],\n",
      "        [ 811.1796],\n",
      "        [ 928.2835],\n",
      "        [ 906.7170],\n",
      "        [ 915.4891],\n",
      "        [ 928.2835],\n",
      "        [ 928.2835],\n",
      "        [ 906.7170],\n",
      "        [ 876.6290],\n",
      "        [ 876.6290],\n",
      "        [ 915.4891],\n",
      "        [ 906.7170],\n",
      "        [ 928.2835],\n",
      "        [ 805.6210],\n",
      "        [ 948.8610],\n",
      "        [ 928.2835],\n",
      "        [ 915.4891],\n",
      "        [ 928.2835],\n",
      "        [ 651.6072],\n",
      "        [ 997.8680],\n",
      "        [ 701.7391],\n",
      "        [ 997.8680],\n",
      "        [ 997.8680],\n",
      "        [ 997.8680],\n",
      "        [ 819.2313],\n",
      "        [ 693.8868],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 698.1032],\n",
      "        [ 819.2313],\n",
      "        [ 997.8680],\n",
      "        [ 997.8680],\n",
      "        [ 690.7031],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 997.8680],\n",
      "        [ 997.8680],\n",
      "        [ 819.2313],\n",
      "        [ 677.3887],\n",
      "        [1004.6142],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 997.8680],\n",
      "        [ 698.1032],\n",
      "        [ 814.6505],\n",
      "        [ 997.8680],\n",
      "        [ 701.0714],\n",
      "        [ 701.0714],\n",
      "        [ 819.2313],\n",
      "        [ 704.7092],\n",
      "        [ 694.8770],\n",
      "        [ 814.6505],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 737.8555],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 997.8680],\n",
      "        [ 694.4388],\n",
      "        [ 678.8906],\n",
      "        [ 997.8680],\n",
      "        [ 733.5370],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 701.0714],\n",
      "        [ 709.6424],\n",
      "        [ 997.8680],\n",
      "        [ 819.2313],\n",
      "        [ 997.8680],\n",
      "        [ 701.0714],\n",
      "        [ 701.0714],\n",
      "        [ 651.6072],\n",
      "        [1004.6142],\n",
      "        [ 997.8680],\n",
      "        [ 997.8680],\n",
      "        [ 997.8680],\n",
      "        [ 817.7811],\n",
      "        [ 694.4388],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 997.8680],\n",
      "        [ 701.0714],\n",
      "        [ 819.2313],\n",
      "        [ 810.3442],\n",
      "        [ 819.2313],\n",
      "        [ 819.2313],\n",
      "        [ 690.7031],\n",
      "        [ 997.8680],\n",
      "        [ 814.6505],\n",
      "        [ 681.6476],\n",
      "        [ 819.2313],\n",
      "        [ 923.0414],\n",
      "        [ 957.8071],\n",
      "        [ 923.0414],\n",
      "        [ 957.8071],\n",
      "        [ 803.1260],\n",
      "        [ 835.2613],\n",
      "        [ 923.0414],\n",
      "        [ 832.5987],\n",
      "        [ 921.1913],\n",
      "        [ 923.0414],\n",
      "        [ 957.8071],\n",
      "        [ 923.0414],\n",
      "        [ 818.8604],\n",
      "        [ 923.0414],\n",
      "        [ 820.0452],\n",
      "        [ 953.1450],\n",
      "        [ 923.0414],\n",
      "        [ 957.8071],\n",
      "        [ 831.8745],\n",
      "        [ 935.1800],\n",
      "        [ 798.2641],\n",
      "        [ 957.8071],\n",
      "        [ 817.3731],\n",
      "        [ 795.4467],\n",
      "        [ 957.8071],\n",
      "        [ 883.3614],\n",
      "        [ 923.0414],\n",
      "        [ 923.0414],\n",
      "        [ 923.0414],\n",
      "        [ 870.7495],\n",
      "        [ 868.5811],\n",
      "        [ 923.0414],\n",
      "        [ 957.8071],\n",
      "        [ 864.8273],\n",
      "        [ 957.8071],\n",
      "        [ 923.0414],\n",
      "        [ 823.9183],\n",
      "        [ 868.5811],\n",
      "        [ 953.1450],\n",
      "        [ 923.0414],\n",
      "        [ 674.0840],\n",
      "        [ 923.0414],\n",
      "        [ 957.8071],\n",
      "        [ 835.2613],\n",
      "        [ 957.8071],\n",
      "        [ 957.8071],\n",
      "        [ 674.0840],\n",
      "        [ 953.1450],\n",
      "        [ 870.7495],\n",
      "        [ 893.8284],\n",
      "        [ 923.0414],\n",
      "        [ 807.9255],\n",
      "        [ 957.8071],\n",
      "        [ 957.8071],\n",
      "        [ 741.9424],\n",
      "        [ 831.8745],\n",
      "        [ 923.0414],\n",
      "        [ 923.0414],\n",
      "        [ 957.8071],\n",
      "        [ 832.5987],\n",
      "        [ 868.5811],\n",
      "        [ 957.8071],\n",
      "        [ 819.2911],\n",
      "        [ 816.4214],\n",
      "        [ 923.0414],\n",
      "        [ 713.5300],\n",
      "        [ 799.1310],\n",
      "        [ 809.5270],\n",
      "        [ 921.1913],\n",
      "        [ 953.1450],\n",
      "        [ 957.8071],\n",
      "        [ 900.5930],\n",
      "        [ 957.8071],\n",
      "        [ 883.3614],\n",
      "        [ 769.6703],\n",
      "        [ 957.8071],\n",
      "        [ 923.0414],\n",
      "        [ 580.9183],\n",
      "        [ 644.0635],\n",
      "        [ 580.9183],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 577.3007],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 569.8390],\n",
      "        [ 685.8911],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 580.9183],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 581.0971],\n",
      "        [ 577.0731],\n",
      "        [ 644.0635],\n",
      "        [ 685.8911],\n",
      "        [ 644.0635],\n",
      "        [ 581.0971],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 581.0971],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 570.3296],\n",
      "        [ 644.0635],\n",
      "        [ 578.5106],\n",
      "        [ 581.0971],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 639.3797],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 581.0971],\n",
      "        [ 644.0635],\n",
      "        [ 685.8911],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 644.0635],\n",
      "        [ 662.5726],\n",
      "        [ 871.4880],\n",
      "        [ 829.3124],\n",
      "        [ 854.5480],\n",
      "        [ 829.3124],\n",
      "        [ 676.6238],\n",
      "        [ 829.3124],\n",
      "        [ 798.9084],\n",
      "        [ 854.5480],\n",
      "        [ 854.5480],\n",
      "        [ 925.4108],\n",
      "        [ 847.1190],\n",
      "        [ 829.3124],\n",
      "        [ 925.4108],\n",
      "        [ 829.3124],\n",
      "        [ 829.3124],\n",
      "        [ 829.3124],\n",
      "        [ 829.3124],\n",
      "        [ 854.5480],\n",
      "        [ 829.3124],\n",
      "        [ 775.0142],\n",
      "        [ 829.3124],\n",
      "        [ 803.5453],\n",
      "        [ 847.1190],\n",
      "        [ 854.5480],\n",
      "        [ 829.3124],\n",
      "        [ 798.9084],\n",
      "        [ 854.5480],\n",
      "        [ 829.3124],\n",
      "        [ 829.3124]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = predict(model)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef0f06b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>915.489075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>820.910278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>915.489075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>854.328064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>817.987732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TRIP_ID  TRAVEL_TIME\n",
       "0      T1   915.489075\n",
       "1      T2   820.910278\n",
       "2      T3   915.489075\n",
       "3      T4   854.328064\n",
       "4      T5   817.987732"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_predict = pd.read_csv('test_public.csv')\n",
    "linear_predict = linear_predict['TRIP_ID']\n",
    "predict_tensor = out.to('cpu').detach().numpy().flatten()\n",
    "linear_predict= pd.concat([linear_predict, pd.DataFrame(predict_tensor)], axis=1)\n",
    "linear_predict = linear_predict.rename(columns={0: 'TRAVEL_TIME'})\n",
    "linear_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ca794bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predict.to_csv('4_layer_MLP_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8f5d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '2_layers_60ep_MLP.pth'\n",
    "torch.save(model.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87df52b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(14,10).to(device)\n",
    "model_state = torch.load('linear.pth')\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a5570eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0353,  1.3840,  8.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
       "        [-1.2917,  0.4417,  8.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
       "        [-1.0353,  1.3840,  8.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000, 12.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, 12.0000,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, 12.0000,  ...,  1.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8519fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use sklearn for something like gradient boosting or random forest\n",
    "\n",
    "#Model Selection: Gradient Boosting,Random Forest,Extra Randomized Trees, SVM, Linear Regression, Logistic Regression, Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: build other models\n",
    "#TODO: report loss on validation sets and tune parameters for each model\n",
    "#TODO: run on test sets and report test loss\n",
    "#TODO: predict travel time(test_features) and submit to kaggle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
