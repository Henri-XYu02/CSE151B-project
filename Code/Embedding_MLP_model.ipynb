{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9381fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.optimizers import SGD, Adam, Adagrad\n",
    "#from keras import backend as K\n",
    "#from keras.layers import Embedding\n",
    "#from keras.layers import Dense, Reshape, Concatenate, Activation, Dropout\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f10fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17119ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cache = 'cache/train.pickle'\n",
    "train_labels_cache = 'cache/train-labels.npy'\n",
    "validation_cache = 'cache/validation.pickle'\n",
    "validation_labels_cache = 'cache/validation-labels.npy'\n",
    "test_cache = 'cache/test.pickle'\n",
    "test_labels_cache = 'cache/test-labels.npy'\n",
    "competition_test_cache = 'cache/competition-test.pickle'\n",
    "metadata_cache = 'cache/metadata.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220a1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cache = 'cache/train2.pickle'\n",
    "train_labels_cache = 'cache/train-labels2.npy'\n",
    "validation_cache = 'cache/validation2.pickle'\n",
    "validation_labels_cache = 'cache/validation-labels2.npy'\n",
    "test_cache = 'cache/test2.pickle'\n",
    "test_labels_cache = 'cache/test-labels2.npy'\n",
    "competition_test_cache = 'cache/competition-test2.pickle'\n",
    "metadata_cache = 'cache/metadata2.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac1c275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(train_cache)\n",
    "validation = pd.read_pickle(validation_cache)\n",
    "test = pd.read_pickle(test_cache)\n",
    "\n",
    "train_labels = np.load(train_labels_cache)\n",
    "validation_labels = np.load(validation_labels_cache)\n",
    "test_labels = np.load(test_labels_cache)\n",
    "\n",
    "competition_test = pd.read_pickle(competition_test_cache)\n",
    "with open(metadata_cache, 'rb') as handle:\n",
    "    metadata = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b1f7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(df):\n",
    "    return torch.tensor(df[['QUARTER_HOUR','DAY_OF_WEEK','WEEK_OF_YEAR','ORIGIN_CALL_ENCODED','TAXI_ID_ENCODED','ORIGIN_STAND_ENCODED',\n",
    "                           'dt_2014-08-14 00:00:00','dt_2014-09-30 00:00:00','dt_2014-10-06 00:00:00','dt_2014-11-01 00:00:00',\n",
    "                           'dt_2014-12-21 00:00:00']].values)\n",
    "#def process_features(df):\n",
    "#    return torch.tensor(df[['QUARTER_HOUR','DAY_OF_WEEK','WEEK_OF_YEAR','ORIGIN_CALL_ENCODED','TAXI_ID_ENCODED',\n",
    "#                            'ORIGIN_STAND_ENCODED']].values)\n",
    "#def process_features(df):\n",
    "#    return torch.tensor(df[['QUARTER_HOUR','DAY_OF_WEEK','WEEK_OF_YEAR','ORIGIN_STAND_ENCODED','dt_2014-08-14 00:00:00','dt_2014-09-30 00:00:00','dt_2014-10-06 00:00:00','dt_2014-11-01 00:00:00',\n",
    "#                           'dt_2014-12-21 00:00:00']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14432b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two layers got 726\n",
    "#Three layers also 726\n",
    "#200 epochs for >=300, three layers 708: 65, 100, 40, 10, 1\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.embed_quarter_hour = nn.Embedding(metadata['n_quarter_hours'], 10)\n",
    "        self.embed_day_of_week = nn.Embedding(metadata['n_days_per_week'], 10)\n",
    "        self.embed_week_of_year = nn.Embedding(metadata['n_weeks_per_year'],10)\n",
    "        self.embed_client_ids = nn.Embedding(metadata['n_client_ids'],10)\n",
    "        self.embed_taxi_ids = nn.Embedding(metadata['n_taxi_ids'],10)\n",
    "        self.embed_stand_ids = nn.Embedding(metadata['n_stand_ids'],10)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=65, out_features=100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features = 100, out_features = 40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features = 40, out_features = 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output_layer = nn.Linear(in_features=10, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        qhr = self.embed_quarter_hour(x[:,0].to(torch.int32))\n",
    "        dow = self.embed_day_of_week(x[:,1].to(torch.int32))\n",
    "        woy = self.embed_week_of_year(x[:,2].to(torch.int32))\n",
    "        ci = self.embed_client_ids(x[:,3].to(torch.int32))\n",
    "        ti = self.embed_taxi_ids(x[:,4].to(torch.int32))\n",
    "        si =  self.embed_stand_ids(x[:,5].to(torch.int32))\n",
    "        x = torch.cat([qhr,dow,woy,ci,ti,si,x[:,6:]],axis=1)\n",
    "        x = x.to(torch.float32)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5960ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "learning_rate = 0.0001\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43647536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300342, 11])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=process_features(train)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ae8513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = process_features(train)\n",
    "train_data = TensorDataset(train_data, torch.tensor(train_labels))\n",
    "validate_data = process_features(validation)\n",
    "validate_data = TensorDataset(validate_data,torch.tensor(validation_labels))\n",
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(validate_data, batch_size = BATCH_SIZE,shuffle=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "all_losses = []\n",
    "train_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3a6175a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9686c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():  # We don't need gradients for validation\n",
    "        for inputs, targets in val_loader:\n",
    "            # Move data to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Reshape targets\n",
    "            targets = torch.reshape(targets,(-1,1))\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = torch.sqrt(criterion(outputs, targets))  # RMSE\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "    # Return average loss\n",
    "    average_val_loss = running_val_loss / len(val_loader)\n",
    "    return average_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9399e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(model, train_loader, val_loader, criterion, num_epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for i,(x, y) in enumerate(train_loader,0):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).to(torch.float32)\n",
    "            y = torch.reshape(y,(-1,1))\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = torch.sqrt(criterion(output, y))#RMSE\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        all_losses.append(epoch_loss/len(train_loader))\n",
    "        print(f\"Epoch: {epoch} Training Loss:{epoch_loss/len(train_loader)}\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val = x_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                y_val = torch.reshape(y_val,(-1,1))\n",
    "                preds = model(x_val)\n",
    "                val_loss += torch.sqrt(criterion(preds, y_val)).item() # RMSE\n",
    "        print(f\"Epoch: {epoch} Validation Loss:{val_loss/len(val_loader)}\")\n",
    "        PATH = f'model_state/model_epoch{epoch}_greater300.pth'     \n",
    "        torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "294a2cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss:841.0045114134442\n",
      "Epoch: 0 Validation Loss:616.4064025878906\n",
      "Epoch: 1 Training Loss:700.5171216095972\n",
      "Epoch: 1 Validation Loss:611.7191963195801\n",
      "Epoch: 2 Training Loss:692.0592989830144\n",
      "Epoch: 2 Validation Loss:605.0415369669596\n",
      "Epoch: 3 Training Loss:686.7024087016005\n",
      "Epoch: 3 Validation Loss:600.1835568745931\n",
      "Epoch: 4 Training Loss:682.3868691924282\n",
      "Epoch: 4 Validation Loss:591.405642191569\n",
      "Epoch: 5 Training Loss:677.6768150508378\n",
      "Epoch: 5 Validation Loss:595.6292152404785\n",
      "Epoch: 6 Training Loss:676.5095269455521\n",
      "Epoch: 6 Validation Loss:597.2507235209147\n",
      "Epoch: 7 Training Loss:672.3801766888456\n",
      "Epoch: 7 Validation Loss:596.9218813578287\n",
      "Epoch: 8 Training Loss:670.4242292224574\n",
      "Epoch: 8 Validation Loss:597.2151196797689\n",
      "Epoch: 9 Training Loss:668.4452725553898\n",
      "Epoch: 9 Validation Loss:592.7480430603027\n",
      "Epoch: 10 Training Loss:664.9556677110864\n",
      "Epoch: 10 Validation Loss:591.9407869974772\n",
      "Epoch: 11 Training Loss:664.2761144520224\n",
      "Epoch: 11 Validation Loss:595.7132987976074\n",
      "Epoch: 12 Training Loss:661.5449860828402\n",
      "Epoch: 12 Validation Loss:586.727793375651\n",
      "Epoch: 13 Training Loss:659.7569869130431\n",
      "Epoch: 13 Validation Loss:589.8842658996582\n",
      "Epoch: 14 Training Loss:659.5710496288896\n",
      "Epoch: 14 Validation Loss:588.97705078125\n",
      "Epoch: 15 Training Loss:657.9177759964516\n",
      "Epoch: 15 Validation Loss:586.8014132181803\n",
      "Epoch: 16 Training Loss:658.6647510504184\n",
      "Epoch: 16 Validation Loss:588.1553268432617\n",
      "Epoch: 17 Training Loss:656.6951993756159\n",
      "Epoch: 17 Validation Loss:583.863161722819\n",
      "Epoch: 18 Training Loss:655.3052821571796\n",
      "Epoch: 18 Validation Loss:578.302817026774\n",
      "Epoch: 19 Training Loss:655.9006389785332\n",
      "Epoch: 19 Validation Loss:587.8063646952311\n",
      "Epoch: 20 Training Loss:654.4467644839781\n",
      "Epoch: 20 Validation Loss:573.7490781148275\n",
      "Epoch: 21 Training Loss:653.1324870788549\n",
      "Epoch: 21 Validation Loss:570.6698290506998\n",
      "Epoch: 22 Training Loss:652.5326355006474\n",
      "Epoch: 22 Validation Loss:582.8988850911459\n",
      "Epoch: 23 Training Loss:652.3196185534184\n",
      "Epoch: 23 Validation Loss:582.3661206563314\n",
      "Epoch: 24 Training Loss:650.9635671608287\n",
      "Epoch: 24 Validation Loss:580.0420214335123\n",
      "Epoch: 25 Training Loss:650.4682109948163\n",
      "Epoch: 25 Validation Loss:581.7847658793131\n",
      "Epoch: 26 Training Loss:650.0815661657501\n",
      "Epoch: 26 Validation Loss:580.4129231770834\n",
      "Epoch: 27 Training Loss:648.5844816281839\n",
      "Epoch: 27 Validation Loss:575.1365954081217\n",
      "Epoch: 28 Training Loss:648.5616271868633\n",
      "Epoch: 28 Validation Loss:578.3887036641439\n",
      "Epoch: 29 Training Loss:648.5279062642511\n",
      "Epoch: 29 Validation Loss:571.5419489542643\n",
      "Epoch: 30 Training Loss:648.1903232465564\n",
      "Epoch: 30 Validation Loss:572.6740125020345\n",
      "Epoch: 31 Training Loss:647.5211218698613\n",
      "Epoch: 31 Validation Loss:581.4651654561361\n",
      "Epoch: 32 Training Loss:644.7171452330892\n",
      "Epoch: 32 Validation Loss:569.29216893514\n",
      "Epoch: 33 Training Loss:645.8897453863975\n",
      "Epoch: 33 Validation Loss:573.453311920166\n",
      "Epoch: 34 Training Loss:644.5297278659009\n",
      "Epoch: 34 Validation Loss:573.5827077229818\n",
      "Epoch: 35 Training Loss:645.1901786293839\n",
      "Epoch: 35 Validation Loss:573.1921310424805\n",
      "Epoch: 36 Training Loss:644.1114073250717\n",
      "Epoch: 36 Validation Loss:577.1822420756022\n",
      "Epoch: 37 Training Loss:644.0215964851656\n",
      "Epoch: 37 Validation Loss:571.1378911336263\n",
      "Epoch: 38 Training Loss:642.4473421724999\n",
      "Epoch: 38 Validation Loss:566.0027516682943\n",
      "Epoch: 39 Training Loss:642.5279167185045\n",
      "Epoch: 39 Validation Loss:574.9770329793295\n",
      "Epoch: 40 Training Loss:641.6085916981577\n",
      "Epoch: 40 Validation Loss:574.3986256917318\n",
      "Epoch: 41 Training Loss:641.7260874165949\n",
      "Epoch: 41 Validation Loss:566.6666119893392\n",
      "Epoch: 42 Training Loss:640.8729086552064\n",
      "Epoch: 42 Validation Loss:564.5738690694174\n",
      "Epoch: 43 Training Loss:640.1436875241332\n",
      "Epoch: 43 Validation Loss:561.4542846679688\n",
      "Epoch: 44 Training Loss:640.0045697570202\n",
      "Epoch: 44 Validation Loss:570.1631825764974\n",
      "Epoch: 45 Training Loss:637.6590505176572\n",
      "Epoch: 45 Validation Loss:566.9264818827311\n",
      "Epoch: 46 Training Loss:638.0976689277327\n",
      "Epoch: 46 Validation Loss:568.1655413309733\n",
      "Epoch: 47 Training Loss:638.491587602691\n",
      "Epoch: 47 Validation Loss:562.3363736470541\n",
      "Epoch: 48 Training Loss:637.5125880913882\n",
      "Epoch: 48 Validation Loss:571.8518816630045\n",
      "Epoch: 49 Training Loss:636.6753950667575\n",
      "Epoch: 49 Validation Loss:563.0248374938965\n",
      "Epoch: 50 Training Loss:636.057704150245\n",
      "Epoch: 50 Validation Loss:569.9150644938151\n",
      "Epoch: 51 Training Loss:636.9755294143163\n",
      "Epoch: 51 Validation Loss:572.353931427002\n",
      "Epoch: 52 Training Loss:634.5358857592472\n",
      "Epoch: 52 Validation Loss:567.5552113850912\n",
      "Epoch: 53 Training Loss:634.1388532380931\n",
      "Epoch: 53 Validation Loss:568.0320688883463\n",
      "Epoch: 54 Training Loss:634.1794119446034\n",
      "Epoch: 54 Validation Loss:566.0574264526367\n",
      "Epoch: 55 Training Loss:633.543717191328\n",
      "Epoch: 55 Validation Loss:561.9234631856283\n",
      "Epoch: 56 Training Loss:633.3477033071432\n",
      "Epoch: 56 Validation Loss:565.7356465657552\n",
      "Epoch: 57 Training Loss:633.6281930722731\n",
      "Epoch: 57 Validation Loss:559.8649342854818\n",
      "Epoch: 58 Training Loss:631.6214889181792\n",
      "Epoch: 58 Validation Loss:559.9062945048014\n",
      "Epoch: 59 Training Loss:630.9660957768768\n",
      "Epoch: 59 Validation Loss:558.2658170064291\n",
      "Epoch: 60 Training Loss:630.0187763982902\n",
      "Epoch: 60 Validation Loss:560.3993161519369\n",
      "Epoch: 61 Training Loss:631.028687017544\n",
      "Epoch: 61 Validation Loss:561.0673522949219\n",
      "Epoch: 62 Training Loss:630.117738675807\n",
      "Epoch: 62 Validation Loss:557.7675272623698\n",
      "Epoch: 63 Training Loss:628.8119097507706\n",
      "Epoch: 63 Validation Loss:565.1425628662109\n",
      "Epoch: 64 Training Loss:627.6529412807989\n",
      "Epoch: 64 Validation Loss:556.1435254414877\n",
      "Epoch: 65 Training Loss:628.0345370045204\n",
      "Epoch: 65 Validation Loss:555.4212443033854\n",
      "Epoch: 66 Training Loss:627.5813222071644\n",
      "Epoch: 66 Validation Loss:555.0004793802897\n",
      "Epoch: 67 Training Loss:626.5988732083179\n",
      "Epoch: 67 Validation Loss:563.4144515991211\n",
      "Epoch: 68 Training Loss:626.5183497373225\n",
      "Epoch: 68 Validation Loss:562.205633799235\n",
      "Epoch: 69 Training Loss:626.6081093721914\n",
      "Epoch: 69 Validation Loss:560.3150075276693\n",
      "Epoch: 70 Training Loss:625.590237357843\n",
      "Epoch: 70 Validation Loss:551.554209391276\n",
      "Epoch: 71 Training Loss:624.5136423586376\n",
      "Epoch: 71 Validation Loss:555.5382893880209\n",
      "Epoch: 72 Training Loss:624.6674811839041\n",
      "Epoch: 72 Validation Loss:557.8356908162435\n",
      "Epoch: 73 Training Loss:625.9324671351559\n",
      "Epoch: 73 Validation Loss:562.7567647298177\n",
      "Epoch: 74 Training Loss:624.0724361957668\n",
      "Epoch: 74 Validation Loss:560.6479530334473\n",
      "Epoch: 75 Training Loss:622.3299008707925\n",
      "Epoch: 75 Validation Loss:558.0557441711426\n",
      "Epoch: 76 Training Loss:621.8312313695842\n",
      "Epoch: 76 Validation Loss:554.8575286865234\n",
      "Epoch: 77 Training Loss:622.9128713392429\n",
      "Epoch: 77 Validation Loss:557.9149055480957\n",
      "Epoch: 78 Training Loss:623.6236197784905\n",
      "Epoch: 78 Validation Loss:553.7746175130209\n",
      "Epoch: 79 Training Loss:622.1428632894678\n",
      "Epoch: 79 Validation Loss:563.5978940327963\n",
      "Epoch: 80 Training Loss:620.7755234486305\n",
      "Epoch: 80 Validation Loss:560.1054573059082\n",
      "Epoch: 81 Training Loss:622.0411652092432\n",
      "Epoch: 81 Validation Loss:549.758903503418\n",
      "Epoch: 82 Training Loss:620.7202611857391\n",
      "Epoch: 82 Validation Loss:555.6190719604492\n",
      "Epoch: 83 Training Loss:619.7589346808884\n",
      "Epoch: 83 Validation Loss:560.7140795389811\n",
      "Epoch: 84 Training Loss:619.5198229288719\n",
      "Epoch: 84 Validation Loss:547.859608968099\n",
      "Epoch: 85 Training Loss:619.7912319786354\n",
      "Epoch: 85 Validation Loss:559.9411735534668\n",
      "Epoch: 86 Training Loss:617.7969478286984\n",
      "Epoch: 86 Validation Loss:553.9620005289713\n",
      "Epoch: 87 Training Loss:618.7303167212299\n",
      "Epoch: 87 Validation Loss:555.9172770182291\n",
      "Epoch: 88 Training Loss:618.443909367552\n",
      "Epoch: 88 Validation Loss:555.1843897501627\n",
      "Epoch: 89 Training Loss:617.7325751390364\n",
      "Epoch: 89 Validation Loss:558.1771087646484\n",
      "Epoch: 90 Training Loss:617.4681340572323\n",
      "Epoch: 90 Validation Loss:560.5698076883951\n",
      "Epoch: 91 Training Loss:615.8286294827423\n",
      "Epoch: 91 Validation Loss:551.6489283243815\n",
      "Epoch: 92 Training Loss:616.3818922786445\n",
      "Epoch: 92 Validation Loss:552.7449760437012\n",
      "Epoch: 93 Training Loss:615.0274670685816\n",
      "Epoch: 93 Validation Loss:553.0777816772461\n",
      "Epoch: 94 Training Loss:615.2993516958568\n",
      "Epoch: 94 Validation Loss:557.872376759847\n",
      "Epoch: 95 Training Loss:615.6309998572813\n",
      "Epoch: 95 Validation Loss:553.6023394266764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96 Training Loss:613.4449508660491\n",
      "Epoch: 96 Validation Loss:539.8410161336263\n",
      "Epoch: 97 Training Loss:615.0054197372352\n",
      "Epoch: 97 Validation Loss:556.5896517435709\n",
      "Epoch: 98 Training Loss:613.0085537507781\n",
      "Epoch: 98 Validation Loss:552.3721987406412\n",
      "Epoch: 99 Training Loss:614.1523413574843\n",
      "Epoch: 99 Validation Loss:556.7738711039225\n",
      "Epoch: 100 Training Loss:612.9898116538816\n",
      "Epoch: 100 Validation Loss:555.1332372029623\n",
      "Epoch: 101 Training Loss:612.2317276813652\n",
      "Epoch: 101 Validation Loss:553.2395985921224\n",
      "Epoch: 102 Training Loss:612.7527664243083\n",
      "Epoch: 102 Validation Loss:554.3772176106771\n",
      "Epoch: 103 Training Loss:612.3197752762003\n",
      "Epoch: 103 Validation Loss:548.3533490498861\n",
      "Epoch: 104 Training Loss:612.2446532084884\n",
      "Epoch: 104 Validation Loss:548.7890243530273\n",
      "Epoch: 105 Training Loss:611.3141256624148\n",
      "Epoch: 105 Validation Loss:556.8169746398926\n",
      "Epoch: 106 Training Loss:610.1551466601729\n",
      "Epoch: 106 Validation Loss:542.9798164367676\n",
      "Epoch: 107 Training Loss:611.4405658918591\n",
      "Epoch: 107 Validation Loss:556.1324144999186\n",
      "Epoch: 108 Training Loss:610.7159954862591\n",
      "Epoch: 108 Validation Loss:554.736432393392\n",
      "Epoch: 109 Training Loss:609.3402943491276\n",
      "Epoch: 109 Validation Loss:554.4637044270834\n",
      "Epoch: 110 Training Loss:610.227523238089\n",
      "Epoch: 110 Validation Loss:552.0752194722494\n",
      "Epoch: 111 Training Loss:607.3572498739248\n",
      "Epoch: 111 Validation Loss:550.587828318278\n",
      "Epoch: 112 Training Loss:608.1817417998084\n",
      "Epoch: 112 Validation Loss:550.756233215332\n",
      "Epoch: 113 Training Loss:608.3463604426861\n",
      "Epoch: 113 Validation Loss:552.341625213623\n",
      "Epoch: 114 Training Loss:607.5100120411155\n",
      "Epoch: 114 Validation Loss:551.6456044514974\n",
      "Epoch: 115 Training Loss:607.1023515880895\n",
      "Epoch: 115 Validation Loss:553.4133377075195\n",
      "Epoch: 116 Training Loss:606.6279636118124\n",
      "Epoch: 116 Validation Loss:546.7021840413412\n",
      "Epoch: 117 Training Loss:607.1246280678292\n",
      "Epoch: 117 Validation Loss:553.7143809000651\n",
      "Epoch: 118 Training Loss:606.9377782079683\n",
      "Epoch: 118 Validation Loss:553.4328346252441\n",
      "Epoch: 119 Training Loss:606.0685465893545\n",
      "Epoch: 119 Validation Loss:552.3176409403483\n",
      "Epoch: 120 Training Loss:605.2899959582088\n",
      "Epoch: 120 Validation Loss:545.5946146647135\n",
      "Epoch: 121 Training Loss:604.8039669626868\n",
      "Epoch: 121 Validation Loss:544.562489827474\n",
      "Epoch: 122 Training Loss:605.4131720290573\n",
      "Epoch: 122 Validation Loss:550.8688570658366\n",
      "Epoch: 123 Training Loss:605.9058191261242\n",
      "Epoch: 123 Validation Loss:550.7579243977865\n",
      "Epoch: 124 Training Loss:603.813227675852\n",
      "Epoch: 124 Validation Loss:552.4214846293131\n",
      "Epoch: 125 Training Loss:603.8238494834038\n",
      "Epoch: 125 Validation Loss:548.5287958780924\n",
      "Epoch: 126 Training Loss:604.4340742555739\n",
      "Epoch: 126 Validation Loss:545.6461232503256\n",
      "Epoch: 127 Training Loss:604.3185393467933\n",
      "Epoch: 127 Validation Loss:557.276658376058\n",
      "Epoch: 128 Training Loss:603.4308969426978\n",
      "Epoch: 128 Validation Loss:545.5936215718588\n",
      "Epoch: 129 Training Loss:602.4475912151817\n",
      "Epoch: 129 Validation Loss:554.2556813557943\n",
      "Epoch: 130 Training Loss:602.8976423656072\n",
      "Epoch: 130 Validation Loss:551.7439905802408\n",
      "Epoch: 131 Training Loss:603.4942950592887\n",
      "Epoch: 131 Validation Loss:546.3688672383627\n",
      "Epoch: 132 Training Loss:600.2153645122513\n",
      "Epoch: 132 Validation Loss:551.7202593485514\n",
      "Epoch: 133 Training Loss:600.5041083135552\n",
      "Epoch: 133 Validation Loss:551.6348787943522\n",
      "Epoch: 134 Training Loss:600.9397286803966\n",
      "Epoch: 134 Validation Loss:547.1909052530924\n",
      "Epoch: 135 Training Loss:600.9804742241799\n",
      "Epoch: 135 Validation Loss:547.4480934143066\n",
      "Epoch: 136 Training Loss:599.4229105952246\n",
      "Epoch: 136 Validation Loss:548.7186533610026\n",
      "Epoch: 137 Training Loss:600.6807405059775\n",
      "Epoch: 137 Validation Loss:553.9653765360514\n",
      "Epoch: 138 Training Loss:599.0015737162176\n",
      "Epoch: 138 Validation Loss:545.3251164754232\n",
      "Epoch: 139 Training Loss:600.618266654614\n",
      "Epoch: 139 Validation Loss:551.0481211344401\n",
      "Epoch: 140 Training Loss:598.8522168400443\n",
      "Epoch: 140 Validation Loss:552.004212697347\n",
      "Epoch: 141 Training Loss:599.1539232394621\n",
      "Epoch: 141 Validation Loss:555.5325724283854\n",
      "Epoch: 142 Training Loss:598.9849498409081\n",
      "Epoch: 142 Validation Loss:550.7760442097982\n",
      "Epoch: 143 Training Loss:599.1307850379765\n",
      "Epoch: 143 Validation Loss:545.4531237284342\n",
      "Epoch: 144 Training Loss:598.6049675049557\n",
      "Epoch: 144 Validation Loss:548.1675198872884\n",
      "Epoch: 145 Training Loss:597.6136072432685\n",
      "Epoch: 145 Validation Loss:552.3333536783854\n",
      "Epoch: 146 Training Loss:596.2045411352508\n",
      "Epoch: 146 Validation Loss:550.0336380004883\n",
      "Epoch: 147 Training Loss:597.6869238718144\n",
      "Epoch: 147 Validation Loss:550.697811126709\n",
      "Epoch: 148 Training Loss:597.0465365630492\n",
      "Epoch: 148 Validation Loss:541.7939236958822\n",
      "Epoch: 149 Training Loss:597.6310433386537\n",
      "Epoch: 149 Validation Loss:547.0299504597982\n",
      "Epoch: 150 Training Loss:596.6665600523525\n",
      "Epoch: 150 Validation Loss:545.0792579650879\n",
      "Epoch: 151 Training Loss:596.9932211057958\n",
      "Epoch: 151 Validation Loss:548.2476170857748\n",
      "Epoch: 152 Training Loss:597.0946428894641\n",
      "Epoch: 152 Validation Loss:550.1740201314291\n",
      "Epoch: 153 Training Loss:595.8482096622892\n",
      "Epoch: 153 Validation Loss:553.2242736816406\n",
      "Epoch: 154 Training Loss:595.7175515706762\n",
      "Epoch: 154 Validation Loss:549.7567240397135\n",
      "Epoch: 155 Training Loss:593.7202056767741\n",
      "Epoch: 155 Validation Loss:546.3745333353678\n",
      "Epoch: 156 Training Loss:595.953118017495\n",
      "Epoch: 156 Validation Loss:550.9204839070638\n",
      "Epoch: 157 Training Loss:595.312433737717\n",
      "Epoch: 157 Validation Loss:546.7758636474609\n",
      "Epoch: 158 Training Loss:594.3687635957306\n",
      "Epoch: 158 Validation Loss:547.9811108907064\n",
      "Epoch: 159 Training Loss:594.108899838578\n",
      "Epoch: 159 Validation Loss:547.8131841023763\n",
      "Epoch: 160 Training Loss:594.3919999553743\n",
      "Epoch: 160 Validation Loss:543.7055651346842\n",
      "Epoch: 161 Training Loss:594.1105651335357\n",
      "Epoch: 161 Validation Loss:546.9437942504883\n",
      "Epoch: 162 Training Loss:594.8641660907292\n",
      "Epoch: 162 Validation Loss:550.9136962890625\n",
      "Epoch: 163 Training Loss:594.7943133308271\n",
      "Epoch: 163 Validation Loss:549.0516408284506\n",
      "Epoch: 164 Training Loss:593.4661493874328\n",
      "Epoch: 164 Validation Loss:544.3525632222494\n",
      "Epoch: 165 Training Loss:594.0253149096794\n",
      "Epoch: 165 Validation Loss:542.6870295206705\n",
      "Epoch: 166 Training Loss:593.4427086497349\n",
      "Epoch: 166 Validation Loss:545.9365247090658\n",
      "Epoch: 167 Training Loss:593.2752813364426\n",
      "Epoch: 167 Validation Loss:546.6284484863281\n",
      "Epoch: 168 Training Loss:594.032673377812\n",
      "Epoch: 168 Validation Loss:554.4491640726725\n",
      "Epoch: 169 Training Loss:592.7724779061576\n",
      "Epoch: 169 Validation Loss:553.0269037882487\n",
      "Epoch: 170 Training Loss:595.1233494242151\n",
      "Epoch: 170 Validation Loss:551.3997090657552\n",
      "Epoch: 171 Training Loss:592.1875871967954\n",
      "Epoch: 171 Validation Loss:545.1858126322428\n",
      "Epoch: 172 Training Loss:590.6829990928204\n",
      "Epoch: 172 Validation Loss:548.280263264974\n",
      "Epoch: 173 Training Loss:592.2708436358874\n",
      "Epoch: 173 Validation Loss:542.4563153584799\n",
      "Epoch: 174 Training Loss:592.4350136430608\n",
      "Epoch: 174 Validation Loss:539.3996136983236\n",
      "Epoch: 175 Training Loss:592.2779012321664\n",
      "Epoch: 175 Validation Loss:549.9775975545248\n",
      "Epoch: 176 Training Loss:592.4928483284428\n",
      "Epoch: 176 Validation Loss:550.6933135986328\n",
      "Epoch: 177 Training Loss:591.4412214931752\n",
      "Epoch: 177 Validation Loss:546.6603495279948\n",
      "Epoch: 178 Training Loss:592.3535473908472\n",
      "Epoch: 178 Validation Loss:550.9225654602051\n",
      "Epoch: 179 Training Loss:590.793997128669\n",
      "Epoch: 179 Validation Loss:544.2072804768881\n",
      "Epoch: 180 Training Loss:590.7358512862164\n",
      "Epoch: 180 Validation Loss:544.8836657206217\n",
      "Epoch: 181 Training Loss:590.9152459240894\n",
      "Epoch: 181 Validation Loss:554.3633550008138\n",
      "Epoch: 182 Training Loss:591.6311401445205\n",
      "Epoch: 182 Validation Loss:547.2714716593424\n",
      "Epoch: 183 Training Loss:591.376364761177\n",
      "Epoch: 183 Validation Loss:550.8304659525553\n",
      "Epoch: 184 Training Loss:591.0485041861743\n",
      "Epoch: 184 Validation Loss:540.3519287109375\n",
      "Epoch: 185 Training Loss:589.5491013528948\n",
      "Epoch: 185 Validation Loss:555.222536722819\n",
      "Epoch: 186 Training Loss:590.5365715270658\n",
      "Epoch: 186 Validation Loss:543.5231920878092\n",
      "Epoch: 187 Training Loss:590.730049760686\n",
      "Epoch: 187 Validation Loss:549.4192822774252\n",
      "Epoch: 188 Training Loss:590.0075496483418\n",
      "Epoch: 188 Validation Loss:547.8587430318197\n",
      "Epoch: 189 Training Loss:589.9888177846511\n",
      "Epoch: 189 Validation Loss:544.8309911092123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190 Training Loss:589.8311547180618\n",
      "Epoch: 190 Validation Loss:543.8695742289225\n",
      "Epoch: 191 Training Loss:590.155090748121\n",
      "Epoch: 191 Validation Loss:538.5910326639811\n",
      "Epoch: 192 Training Loss:589.0018894632776\n",
      "Epoch: 192 Validation Loss:546.5096842447916\n",
      "Epoch: 193 Training Loss:590.2908757018392\n",
      "Epoch: 193 Validation Loss:541.3605893452963\n",
      "Epoch: 194 Training Loss:588.6300548395808\n",
      "Epoch: 194 Validation Loss:548.1190172831217\n",
      "Epoch: 195 Training Loss:589.0216808343472\n",
      "Epoch: 195 Validation Loss:549.4635162353516\n",
      "Epoch: 196 Training Loss:587.9160464936538\n",
      "Epoch: 196 Validation Loss:540.5335528055826\n",
      "Epoch: 197 Training Loss:588.1796015384708\n",
      "Epoch: 197 Validation Loss:549.0305836995443\n",
      "Epoch: 198 Training Loss:587.557688325834\n",
      "Epoch: 198 Validation Loss:548.5306243896484\n",
      "Epoch: 199 Training Loss:588.4573068314021\n",
      "Epoch: 199 Validation Loss:553.3724517822266\n"
     ]
    }
   ],
   "source": [
    "train_data(model, train_loader, val_loader, criterion, 200) # use the training function you defined\n",
    "val_loss = validate(model, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a69baea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3dfc1d4760>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD5CAYAAADcDXXiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAi/UlEQVR4nO3deZxU5Z3v8c+vqnqHpruhgW6gaUBAAQW1xS0uibtJJCaTBBMzxpiQzGiMmcm9o8m9SWbm5o7xZn9NNjUmGrcYl8gkGo0mUW8ElFUBWZqlgQaaBhp636p+80cVUL3S2HRXV/X3/Xr1q6uec6rqV6eKL08/5znnmLsjIiKpJZDoAkRE5ORTuIuIpCCFu4hIClK4i4ikIIW7iEgKUriLiKSgUF9WMrMvA58FHHgbuBm4E/gcUB1b7avu/lxs/buAW4AwcLu7v9Db848ZM8ZLS0vfTf0iIsPWihUr9rt7YXfLjhvuZjYBuB2Y5e5NZvYEsDC2+Pvu/p1O68+KLZ8NFAMvmdkMdw/39BqlpaUsX768b+9GREQAMLOKnpb1dVgmBGSZWQjIBnb3su4C4HF3b3H3bUA5ML+vxYqISP8dN9zdvRL4DrAD2AMcdvcXY4tvM7O3zOwBM8uPtU0AdsY9xa5YWwdmtsjMlpvZ8urq6s6LRUSkH44b7rHQXgBMITrMkmNmNwI/BaYB84iG/nePPKSbp+lyjgN3v9fdy9y9rLCw2yEjERF5l/oyLHM5sM3dq929DXgauMDdq9w97O4R4D6ODb3sAibFPX4ivQ/jiIjISdaXcN8BnGdm2WZmwGXAO2ZWFLfO9cDa2O3FwEIzyzCzKcB04I2TWbSIiPTuuLNl3H2ZmT0JrATagVXAvcD9ZjaP6JDLduDzsfXXxWbUrI+tf2tvM2VEROTks6Fwyt+ysjLXVEgRkRNjZivcvay7ZUl9hOqew01878WNbK2uT3QpIiJDSlKH+77aFn7053K2H2hIdCkiIkNKUod7MBCdddkeTvzQkojIUJIS4R4ZAvsNRESGkqQO99CRnntE4S4iEi+pwz0QC/ewwl1EpIOkDveQwl1EpFtJHe4B07CMiEh3kjrcQ8HYDlWFu4hIB0kd7kHtUBUR6VZyh7tpzF1EpDtJHe6hQLR8hbuISEdJHe6xbFe4i4h0ktThfrTnriNURUQ6SOpwV89dRKR7SR3uGnMXEeleUod7bCakpkKKiHSS1OFuZgQDRjgSSXQpIiJDSlKHOxAL90RXISIytCR/uJt67iIinSV9uIfUcxcR6SLpwz2gMXcRkS6SPtxDAdNBTCIinSR9uEd3qCrcRUTipUS4t4cV7iIi8VIi3DUsIyLSUWqEu4ZlREQ6ULiLiKSgpA/3kMJdRKSLpA/3gCncRUQ661O4m9mXzWydma01s8fMLNPMCszsT2a2OfY7P279u8ys3Mw2mtlVA1c+hIIKdxGRzo4b7mY2AbgdKHP3OUAQWAjcCbzs7tOBl2P3MbNZseWzgauBn5hZcGDKj55bRqf8FRHpqK/DMiEgy8xCQDawG1gAPBhb/iDwodjtBcDj7t7i7tuAcmD+Sau4k2DAiGgqpIhIB8cNd3evBL4D7AD2AIfd/UVgnLvvia2zBxgbe8gEYGfcU+yKtXVgZovMbLmZLa+urn7Xb0AHMYmIdNWXYZl8or3xKUAxkGNmN/b2kG7auqSvu9/r7mXuXlZYWNjXervQQUwiIl31ZVjmcmCbu1e7exvwNHABUGVmRQCx3/ti6+8CJsU9fiLRYZwBEQoEtENVRKSTvoT7DuA8M8s2MwMuA94BFgM3xda5CXg2dnsxsNDMMsxsCjAdeOPkln1MQPPcRUS6CB1vBXdfZmZPAiuBdmAVcC8wAnjCzG4h+h/AR2PrrzOzJ4D1sfVvdffwANWvg5hERLpx3HAHcPdvAN/o1NxCtBff3frfAr7Vv9L6JqCpkCIiXST9EaqhgBFRuIuIdJD04R4MGO26zJ6ISAcpEe7quIuIdJT04R5Sz11EpIukD/dAwFC2i4h0lPThrp67iEhXSR/uOohJRKSrpA93HcQkItJV0od7dCqkwl1EJF7yh7vpICYRkc6SP9yD6rmLiHSW/OFuuhKTiEhnSR/uIY25i4h0kfThHggY7mjcXUQkTtKHeygQvaqfLrUnInJM0od7MBB9C5rrLiJyTAqEe/S3wl1E5JgUCPfoW9BOVRGRY5I/3KND7tqhKiISJ/nDPaieu4hIZ0kf7kdnyyjcRUSOSvpwD5qmQoqIdJb84X6k5x5WuIuIHJE64a6eu4jIUakT7rrUnojIUSkT7potIyJyTMqEu2bLiIgck/ThrqmQIiJdJX24BxTuIiJdJH24q+cuItLVccPdzGaa2eq4n1ozu8PMvmlmlXHt18Y95i4zKzezjWZ21UC+gaMHMSncRUSOCh1vBXffCMwDMLMgUAk8A9wMfN/dvxO/vpnNAhYCs4Fi4CUzm+Hu4ZNbepR2qIqIdHWiwzKXAVvcvaKXdRYAj7t7i7tvA8qB+e+2wOPRVEgRka5ONNwXAo/F3b/NzN4yswfMLD/WNgHYGbfOrlhbB2a2yMyWm9ny6urqEyzjGB2hKiLSVZ/D3czSgeuA38aafgpMIzpkswf47pFVu3l4l+R193vdvczdywoLC0+k5g5CRy6zp3PLiIgcdSI992uAle5eBeDuVe4edvcIcB/Hhl52AZPiHjcR2H0yiu1O4Mhl9tRzFxE56kTC/QbihmTMrChu2fXA2tjtxcBCM8swsynAdOCN/hbak5AukC0i0sVxZ8sAmFk2cAXw+bjme8xsHtEhl+1Hlrn7OjN7AlgPtAO3DtRMGdAFskVEutOncHf3RmB0p7ZP9bL+t4Bv9a+0vgmq5y4i0kXKHKGqqZAiIsckfbgfObdMROEuInJU0oe7eu4iIl0lfbgHdIFsEZEukj7cj54VMqzL7ImIHJH04X70fO7quIuIHJX04R7SBbJFRLpI+nDXWSFFRLpKmXDXVEgRkWOSP9xNPXcRkc6SPtwDAcNMPXcRkXhJH+4Q3amqnruIyDEpEe7BgOkgJhGROKkR7ma6EpOISJzUCHcNy4iIdJAy4R7RsIyIyFEpEu4B9dxFROKkSLhrKqSISLyUCPeQeu4iIh2kRLgHA6aeu4hInJQJd/XcRUSOSZlwDyvcRUSOSo1wN4W7iEi81Ah3DcuIiHSQMuGug5hERI5JmXBXz11E5JiUCPeQpkKKiHSQEuEeCBjtukC2iMhRKRHuIU2FFBHpICXCXfPcRUQ6Om64m9lMM1sd91NrZneYWYGZ/cnMNsd+58c95i4zKzezjWZ21cC+BYW7iEhnxw13d9/o7vPcfR5wNtAIPAPcCbzs7tOBl2P3MbNZwEJgNnA18BMzCw5M+VEhXWZPRKSDEx2WuQzY4u4VwALgwVj7g8CHYrcXAI+7e4u7bwPKgfknodYeBQNGa7t2qIqIHHGi4b4QeCx2e5y77wGI/R4ba58A7Ix7zK5YWwdmtsjMlpvZ8urq6hMso6PS0Tls399Ic1u4X88jIpIq+hzuZpYOXAf89nirdtPWZczE3e919zJ3LyssLOxrGd06e3I+reEIaysP9+t5RERSxYn03K8BVrp7Vex+lZkVAcR+74u17wImxT1uIrC7v4X25uzJ0X25b26vGciXERFJGicS7jdwbEgGYDFwU+z2TcCzce0LzSzDzKYA04E3+ltob0aPyGDqmBxWVBwcyJcREUkafQp3M8sGrgCejmu+G7jCzDbHlt0N4O7rgCeA9cAfgVvdfcAHw8tK81leUaPTEIiI0Mdwd/dGdx/t7ofj2g64+2XuPj32+2Dcsm+5+zR3n+nuzw9E4Z2VTS7gUGMbW/fXD8bLiYgMaSlxhCrA/CkFAPx1Y/9m3oiIpIKUCffSMTnMmZDL71ZXJroUEZGES5lwB/jwmRNZW1nLpqq6RJciIpJQKRXu180rJhgwnl6p3ruIDG8pFe5jRmRw6YxCnl65S6cjEJFhLaXCHeBT509mX10L/7VmQI+bEhEZ0lIu3C+ZUcjMcSO577WtuM4UKSLDVMqFu5nxuYunsmFvHa9t3p/ockREEiLlwh3gurnFjBmRwYOvb090KSIiCZGS4Z4eCnDD/En8eeM+dh5sTHQ5IiKDLiXDHeAT55YQMOORZTsSXYqIyKBL2XAvGpXFFaeN41evb+Mnfy3X1EgRGVZSNtwB/m3BbC6eXsg9f9zID17alOhyREQGTUqH+9jcTO79+zLef0YRDy2p4HBTW6JLEhEZFCkd7kf846XTqG9p59dLtie6FBGRQTEswn128SjeO7OQ+17bxpZqne9dRFLfsAh3gP/1gVmkBY0b7l2qgBeRlDdswn1a4Qge/dx5hCPODfcuZasCXkRS2LAJd4AZ40by2KJowH/ivmXawSoiKWtYhTtEA/6BT59DVV0zP/5LeaLLEREZEMMu3AHmTsrj786ayC//to3t+xsSXY6IyEk3LMMd4CtXzSQtGOCqH7zKHY+voqk1nOiSREROmmEb7uNyM3n6Hy/g4+dM4tk1u/k/f1if6JJERE6aUKILSKRTx+fybwvmkJUW5OevbuXCU8Zw7elFiS5LRKTfhm3PPd4/XzmTeZPyuP2xVTy5YhcNLe2JLklEpF8U7kTP//7QLfM5e3I+X/ntGmZ/4wU+ef9Sahpa2ba/gcpDTYkuUUTkhNhQuM5oWVmZL1++PNFl0NwW5sX1VZRX1fGzV7aSEQpQ19JOXnYaD99yLnMmjEp0iSIiR5nZCncv626Zeu5xMtOCXDe3mH+6ciaPLTqX86eN5n9cNZOc9BA3/mIZr5dHr8la19ymi2+LyJCmnnsf7DjQyKd/9Qbb9jdQUpBNxYFGrp49nv/48Onk56QnujwRGabUc++nktHZ/P6L7+EzF06hdHQOn76glJc3VHH1D1/ltc3ViS5PRKSLPvXczSwPuB+YAzjwGeAq4HPAkXT7qrs/F1v/LuAWIAzc7u4v9Pb8Q73n3p21lYe54zerKd9Xz/zSAi48ZQwT8rO4/LSx5GWrNy8iA6+3nntfw/1B4DV3v9/M0oFs4A6g3t2/02ndWcBjwHygGHgJmOHuPR4CmozhDtDUGub+17by3Nq9vLOnFoCxIzP41+tmc8nMQrLTh/VhBCIywHoL9+Omj5nlAhcDnwZw91ag1cx6esgC4HF3bwG2mVk50aBfcuKlD21Z6UG+eNl0vnjZdJrbwqzbfZg7n3qbf3hkJcGAcVrRSC48ZQy3v286ORkKehEZPH1JnKlEh15+aWZzgRXAl2LLbjOzvweWA//s7jXABGBp3ON3xdo6MLNFwCKAkpKSd/0GhorMtCBnTy7g97e/h9fLD7ByRw0rKmq479WtvLS+ik+dN5lgMEAoYIwdmcFpRbkU52UlumwRSVHHHZYxszKiYX2huy8zsx8CtcB/AvuJjsH/O1Dk7p8xsx8DS9z94djjfwE85+5P9fQayTos0xevb9nPlx5fTXVdS5dlcybk8qXLZnDFrHEJqExEkl2/hmWI9rx3ufuy2P0ngTvdvSruBe4Dfh+3/qS4x08Edp9w1SnigmljeP3O91HX3E57JEI44uw+1MTKikP8ZvlObnt0JX+4/SKCAcPdmVo4ItEli0gKOG64u/teM9tpZjPdfSNwGbDezIrcfU9steuBtbHbi4FHzex7RHeoTgfeGIDak0ZaMEBB3Hz4olFZnD25gAXzirnqB69y4/3LqK5vIWDwuYumsre2maAZX3zfdEpGZyewchFJVn3dy/dF4JHYTJmtwM3Aj8xsHtFhme3A5wHcfZ2ZPQGsB9qBW3ubKTOcjc3N5O6PnMFtj67ko2dP5HBTGz/56xZGZaXR2h7h6VWVFOSkM7s4l3s+cgZjczMTXbKIJAkdoToEtIUjpAUDuDs7DjZSNCqLmsZWHl5awb7aFhav2c3IzBDzJuVRkJPOTReUMnl0NgEzMtOCiS5fRBKk3/PcB9pwD/fjWb+7lq8/u5b6lnZ2HGykMXbVqPRQgGvnjOeT502mbHI+vUxPFZEUpHBPIYcb23h61S5a2iNU1jTxu1WV1LW0MyEvi6JRmdx84RTef4YuOCIyHPR3towMIaOy07j5wilH79917an8fs0eXtlUzTt7a/nS46vIz05jzMgMVu84xO7DTVw3t1izcESGGfXcU0htcxsf/snrlO+r79BuBlfNGs+iS6Zy5qQ8mtrCLNlygIumF5Ie0rnjRJKVeu7DRG5mGr/89Dk8vLSCGeNGMq8kj5GZIR56vYKHlmznj+v2UlKQTW1zG4ca2/h42STu/sjpGqsXSUHquQ8T9S3tLF69mz+t30tmWpC87DQee2MnX7hkGlfNHkdGKEh+ThpFo3RKBJFkoZ67MCIjxCfOLeET50bP4xOJOIca2/jZK1v42Stbjq53+oRRzBw/klDAqKpt5lPnT+Z9p+r0CCLJRj33Yczd2VXTxIa9dYQjEbbtb+QvG/axs6aRtnCEYMA42NDKf37iLK6aPT7R5YpIJ5oKKe9KbXMbN96/jLd2HWbGuBHcML+Ec0oLeGTZDgpHZvD3509mzIiMRJcpMmwp3OVdq29p58nlO3l2zW5W7TgEQGZagJb2CJmhIHdcPp3PvGcKaUHNuhEZbAp3OSmWbT3A2t21fGheMTWNbdz9/AZeeqeK04pyueuaU6lvaScjFOCsknxdOFxkECjcZUC4Oy+s28s3Fq+jqvbY+eoDBh+aN4EFZ04gOz1Ic1uYCXlZOpBK5CTTbBkZEGbG1XOKuPCUMby6aT8lBdk0trbz4voqHllWwdOrKuPWhevnTeDLV8xgUkE27eEID/xtG+X76vnGB2frMoQiJ5l67jIgDja0Ur6vnpb2MOnBAH/euI9f/W07EXfOnzaGnQcb2ba/AYC5E0fxy5vndzjnvYgcn4ZlZEjYc7iJH71czuqdhxidk84nzy0hFAxw26MrmZifxa9vOZfivCz2HG7ioSUVvLB2L2dMHMW/LpjDqKy0RJcvMuQo3GVIW7b1AJ99cDlmUFZawN/K99Meccom57OiooZxuZn86IZ51LeEeXLFLr5wyVRmF49KdNkiCadwlyFv4946fv7KFlbuqGHupDy+cuVMJhVks2pHDbc/vorKmiYiHh27D5rx2YumsujiqRrKkWFN4S5Jrba5jXv+uIHRORl88twS7n5+A8+sriQtEKBkdDbuTm1zO1//wCw+OLeY/fUtjMgI6SpVkvIU7pJyNlfV8dsVu6g40IBhVB5qYv2eWs4pzWfp1oOYwSmFI1gwr5h5k/I5rWgko3U0raQYhbukvIaWdm7+5ZuUV9dz47klBAMB/la+nze2HwQgOz3IDz4+j1PH51LX0qYxe0kJCncZFsIRx90JxZ0KYV9dM+X76vn28xtYs+vw0fa/O3si80sL2LK/np0HG/nAGcVce3oR+2qbyc4IMULz7iUJKNxl2GtuC3P/a1sZkRGiqq6Fn7+yhYhDejDAyMwQh5ra+Ox7pvDQkgqKRmXy8GfP5W/l+0kPBfjgGcUEArqgiQw9CneRTnYebCQccSbmZ9HSHmHhvUt5u/IwcyeOYvO+elrbI7RHov825k7K47PvmcK43EzerjzMlDHZTCscwYiMkMbxJaEU7iLHcbChlT9v2Md1c4tZvfMQP3p5M586fzINLe1898VNVB5q6vZx500t4Pb3TeeCU8awqaqOd/bUcunMsTroSgaFwl2kH8IRZ8mWA9S3tHNmSR7b9jewq6aJvYebeHjpDvbWNjO/tICVO2pojzjpoQCLLprKzReW8tzavVw4bbROmiYDQuEuMkBa2sPc/9o2fvrXLVx+2lgWzi/hN2/u5JlVlZiBO0wrzOEPt19EZloQd6c94jr/vZwUCneRARaJeIedri+u28uybQcpHZPD//7dWi6dWcjew81sqa7HMN5/RhHXzSvmrJL8o0M4h5vayEkPdpjtI9IbnfJXZIB1nk1z5ezxXBm77uzmqjoeWlIR3TF70VTqmtv43ardPBM7JfL0sSNoaguzq6YJM5hVlMuN501mwbxistM7/hM9UN9CQU46Zpq9I71Tz11kgIUjzs6DjZSOyTna1tjazuodh1i5o4aVOw6RFjTOLMmnsSV6PvwNe+vIzQzxgbnFzJuUx/rdtby6qZqt+xv4xLklfOtDcxTwomEZkWTi7iyvqOHB17fzlw37aGgNkxEKcN7U0eRmpfFfa3bz/jOKKB6VyZKtB9i4t46cjBCXzCjkHy6dxqnjc48+z5bqegpHZDIqW7N3UlG/h2XMLA+4H5gDOPAZYCPwG6AU2A58zN1rYuvfBdwChIHb3f2Ffr0DkWHEzDintIBzSgtoD0fYtr+BSQXZR3fIjhuZwYNLtgNw+oRR3HzhFA41tvKHt/bw7OrdXH7aWPKy01my5QCVh5o4sySPp75wgQ7EGmb61HM3sweB19z9fjNLB7KBrwIH3f1uM7sTyHf3fzGzWcBjwHygGHgJmOHu4Z6eXz13kf471NjKg69X8MvXt2HAOaUFjMvN5NdLK7jnI2fwsXMmcbChlQ17amluDzNj3Egm5kfPqhmOHDttg7tryCdJ9GtYxsxygTXAVI9b2cw2Ape6+x4zKwL+6u4zY7123P0/Yuu9AHzT3Zf09BoKd5GTJxJxzKJ/AUQizsd+voQNe+sYlZXW4WCsrLQgX75iOk+vrKS5Lcz3Pz6PH/9lC1v31/OLm85hStw+Ahma+hvu84B7gfXAXGAF8CWg0t3z4tarcfd8M/tPYKm7Pxxr/wXwvLs/2el5FwGLAEpKSs6uqKh4d+9ORHq1qaqOrz+7lnG5mcwcP5K5E/PICAW4+/kNLK+oYXxuJu2RCPvrWwkFjJyMEMGAUVKQzeGmNvKy02huixAwOHfKaD5y9gSdVXOI6G+4lwFLgQvdfZmZ/RCoBb7YQ7j/GFjSKdyfc/enenoN9dxFBl9re4SX3qniouljONTYxnde3MjCc0oYl5vBV595m4AZ+TnpHG5sIzMtQGNrmOUVNbS2R7j29PH863VzeGdPLU+t3EVZaQHNrWE2VdVx/VkTmDsxj+0HGqhtaqd0TDZFo7IS/XZTUn/DfTzRnnhp7P5FwJ3AKWhYRmRYOdzUxgP/fxs/e2ULmWlBapvbyEoL0tga3aWWnX7s9hHpoQBffO8pzJ9SwMzxI8nLTqfyUBObquo4f+poXTGrH/o1W8bd95rZTjOb6e4bgcuIDtGsB24C7o79fjb2kMXAo2b2PaI7VKcDb/T/bYhIoo3KSuPLV8zg/WcUcedTbzFz/Ei+/oHZVB5qIjMtwJgRGTy9spID9S1MGzuCkZkhHl22g+/+aRMAo3PS+eHCM/mXp96i8lATOelBPlo2iZsuKKWkIJv65nZqm9sYm5vBsq0HeWPbQdJDAd536ljmTOh9KGjv4Wa+96eN3PreU5g8WvsL+jpbZh7RqZDpwFbgZiAAPAGUADuAj7r7wdj6XyM6XbIduMPdn+/t+dVzF0ltm6vq2HGwkbuefpt9dS1kpwf55nWzWbrlAIvX7KY94gQDRjjSMY+OnJ8nGDAWzC1m6/4GcjKCXDy9kKK8LFbvOMTyioMsPKeEx97YwduVhzl7cj5PfP58gsNg6qcOYhKRIaF8Xz1fe+Zt/vG9p3DJjEIAdtU08sqmaiprmsjLTiM3M43dh5qYMX4kV8waR3NbhH///XqeXV3J6RNGUdfczuZ99QCkBY1JBdlsrW7ADD5eNonH39zJndecyhcumcbqnYd47u09HGxoJTs9SCgQYH99CxfPKOTi6WP47YpdnDe1gLMnF3So80guDvUpoQp3EUl68SdnO9jQyv76FgpHZDAqK42nVu4iKz3I+08v4gsPr+CFdVVcOWscf9m4DzNjdE46ja1h2sIRcjJCVNe1HH3eUMC4/bLpnDJ2BPUt7WzcW8d/rdlNc1uYKYUjmDomh6vnjOeq2eNpaIn+x1Lb1MaZJXmMzEzskb8KdxEZNlrbI/zf597hV69v55IZhfzohjM7XDwlEnGeX7uX9XsOc/XsIn748iZeemff0eVpQePSmWMZn5vJtv0NbKqqY19dC5efNpY3t9dwuKkNgMy0AGeV5DMiI0R2epCmtjA7DzZx5exxzBg3km//cQNXzx7P/7z61AEbIlK4i8iwU3GggYn52ccNVndn58EmGtvayUkPUTgyo8MMnrZwhHv+uIH7XtvG5aeN46NlE8lKC/LCur28s6eWxtYwja1h0oJGfnY6yytqABiXm0FVbQvTCnM41NjG2ZPz+fwl06hvaWdifhZFozJ54s2djB6RwQfnFr+r96hwFxHpp4aWdnIyjn86rqVbD7C5qo6F80t4/M2dLF5dSXFeFi+tr6IhbppoeihAa3uE68+cwPc/Pu9d1aRwFxFJsOq6FpZuPUDhyAw27q1jU1UdHz5rQpeduSdCF+sQEUmwwpHHhl/Omzp6wF9P1/MSEUlBCncRkRSkcBcRSUEKdxGRFKRwFxFJQQp3EZEUpHAXEUlBCncRkRQ0JI5QNbNqoD8XUR0D7D9J5ZxMquvEqK4TN1RrU10n5t3WNdndC7tbMCTCvb/MbHlPh+Amkuo6MarrxA3V2lTXiRmIujQsIyKSghTuIiIpKFXC/d5EF9AD1XViVNeJG6q1qa4Tc9LrSokxdxER6ShVeu4iIhJH4S4ikoKSOtzN7Goz22hm5WZ2ZwLrmGRmfzGzd8xsnZl9Kdb+TTOrNLPVsZ9rE1DbdjN7O/b6y2NtBWb2JzPbHPudn4C6ZsZtl9VmVmtmdyRim5nZA2a2z8zWxrX1uI3M7K7Yd26jmV01yHX9PzPbYGZvmdkzZpYXay81s6a47fazgaqrl9p6/OwSvM1+E1fTdjNbHWsftG3WS0YM3PfM3ZPyBwgCW4CpQDqwBpiVoFqKgLNit0cCm4BZwDeBryR4O20HxnRquwe4M3b7TuDbQ+Cz3AtMTsQ2Ay4GzgLWHm8bxT7XNUAGMCX2HQwOYl1XAqHY7W/H1VUav16Ctlm3n12it1mn5d8Fvj7Y26yXjBiw71ky99znA+XuvtXdW4HHgQWJKMTd97j7ytjtOuAdYEIiaumjBcCDsdsPAh9KXCkAXAZscff+HKX8rrn7q8DBTs09baMFwOPu3uLu24Byot/FQanL3V909/bY3aXAxIF47ePpYZv1JKHb7AgzM+BjwGMD8dq96SUjBux7lszhPgHYGXd/F0MgUM2sFDgTWBZrui32J/QDiRj+ABx40cxWmNmiWNs4d98D0S8dMDYBdcVbSMd/cIneZtDzNhpK37vPAM/H3Z9iZqvM7BUzuyhBNXX32Q2VbXYRUOXum+PaBn2bdcqIAfueJXO4WzdtCZ3XaWYjgKeAO9y9FvgpMA2YB+wh+ifhYLvQ3c8CrgFuNbOLE1BDj8wsHbgO+G2saShss94Mie+dmX0NaAceiTXtAUrc/Uzgn4BHzSx3kMvq6bMbEtsMuIGOnYhB32bdZESPq3bTdkLbLJnDfRcwKe7+RGB3gmrBzNKIfmiPuPvTAO5e5e5hd48A9zFAf4r2xt13x37vA56J1VBlZkWxuouAfYNdV5xrgJXuXgVDY5vF9LSNEv69M7ObgA8An/TYAG3sz/cDsdsriI7RzhjMunr57IbCNgsBHwZ+c6RtsLdZdxnBAH7Pkjnc3wSmm9mUWO9vIbA4EYXExvJ+Abzj7t+Lay+KW+16YG3nxw5wXTlmNvLIbaI749YS3U43xVa7CXh2MOvqpENvKtHbLE5P22gxsNDMMsxsCjAdeGOwijKzq4F/Aa5z98a49kIzC8ZuT43VtXWw6oq9bk+fXUK3WczlwAZ333WkYTC3WU8ZwUB+zwZjT/EA7oG+luhe5y3A1xJYx3uI/sn0FrA69nMt8Gvg7Vj7YqBokOuaSnSP+xpg3ZFtBIwGXgY2x34XJGi7ZQMHgFFxbYO+zYj+57IHaCPaY7qlt20EfC32ndsIXDPIdZUTHYs98j37WWzdj8Q+4zXASuCDCdhmPX52idxmsfZfAV/otO6gbbNeMmLAvmc6/YCISApK5mEZERHpgcJdRCQFKdxFRFKQwl1EJAUp3EVEUpDCXUQkBSncRURS0H8Dr6ot88g1HQEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(torch.Tensor.cpu(torch.tensor(all_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79010bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_loss(model, test_set, test_label,criterion):\n",
    "    total_loss=0\n",
    "    test_dataset = TensorDataset(test_set, test_label)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y = torch.reshape(y,(-1,1))\n",
    "        output = model(x)\n",
    "        loss = torch.sqrt(criterion(output, y))#RMSE\n",
    "        total_loss += loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e66fcbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, test loss: 656.8514404296875\n",
      "epoch: 1, test loss: 652.489501953125\n",
      "epoch: 2, test loss: 656.1748046875\n",
      "epoch: 3, test loss: 648.8671264648438\n",
      "epoch: 4, test loss: 643.8526611328125\n",
      "epoch: 5, test loss: 649.3121337890625\n",
      "epoch: 6, test loss: 644.5361938476562\n",
      "epoch: 7, test loss: 637.3853759765625\n",
      "epoch: 8, test loss: 641.1902465820312\n",
      "epoch: 9, test loss: 634.7704467773438\n",
      "epoch: 10, test loss: 630.18310546875\n",
      "epoch: 11, test loss: 635.7705078125\n",
      "epoch: 12, test loss: 630.619873046875\n",
      "epoch: 13, test loss: 637.5054321289062\n",
      "epoch: 14, test loss: 638.4015502929688\n",
      "epoch: 15, test loss: 636.194091796875\n",
      "epoch: 16, test loss: 634.5285034179688\n",
      "epoch: 17, test loss: 634.40576171875\n",
      "epoch: 18, test loss: 638.10595703125\n",
      "epoch: 19, test loss: 632.1621704101562\n",
      "epoch: 20, test loss: 635.1085815429688\n",
      "epoch: 21, test loss: 640.7289428710938\n",
      "epoch: 22, test loss: 632.3276977539062\n",
      "epoch: 23, test loss: 634.2333374023438\n",
      "epoch: 24, test loss: 634.9292602539062\n",
      "epoch: 25, test loss: 623.6168212890625\n",
      "epoch: 26, test loss: 631.0741577148438\n",
      "epoch: 27, test loss: 625.8612670898438\n",
      "epoch: 28, test loss: 620.2443237304688\n",
      "epoch: 29, test loss: 626.281005859375\n",
      "epoch: 30, test loss: 627.82177734375\n",
      "epoch: 31, test loss: 618.9560546875\n",
      "epoch: 32, test loss: 627.8688354492188\n",
      "epoch: 33, test loss: 621.3035278320312\n",
      "epoch: 34, test loss: 610.1788940429688\n",
      "epoch: 35, test loss: 627.4100341796875\n",
      "epoch: 36, test loss: 618.8984985351562\n",
      "epoch: 37, test loss: 615.4285278320312\n",
      "epoch: 38, test loss: 624.1220703125\n",
      "epoch: 39, test loss: 618.329833984375\n",
      "epoch: 40, test loss: 621.208984375\n",
      "epoch: 41, test loss: 612.0953369140625\n",
      "epoch: 42, test loss: 611.3651123046875\n",
      "epoch: 43, test loss: 619.5086669921875\n",
      "epoch: 44, test loss: 615.3025512695312\n",
      "epoch: 45, test loss: 619.8528442382812\n",
      "epoch: 46, test loss: 619.2750244140625\n",
      "epoch: 47, test loss: 603.4244995117188\n",
      "epoch: 48, test loss: 617.0872192382812\n",
      "epoch: 49, test loss: 616.7343139648438\n",
      "epoch: 50, test loss: 615.7906494140625\n",
      "epoch: 51, test loss: 617.8464965820312\n",
      "epoch: 52, test loss: 601.2372436523438\n",
      "epoch: 53, test loss: 611.5890502929688\n",
      "epoch: 54, test loss: 593.3096313476562\n",
      "epoch: 55, test loss: 613.9854125976562\n",
      "epoch: 56, test loss: 615.6629638671875\n",
      "epoch: 57, test loss: 605.1661987304688\n",
      "epoch: 58, test loss: 609.3175048828125\n",
      "epoch: 59, test loss: 600.5851440429688\n",
      "epoch: 60, test loss: 611.07177734375\n",
      "epoch: 61, test loss: 609.312744140625\n",
      "epoch: 62, test loss: 606.776123046875\n",
      "epoch: 63, test loss: 608.1132202148438\n",
      "epoch: 64, test loss: 598.5204467773438\n",
      "epoch: 65, test loss: 602.8594970703125\n",
      "epoch: 66, test loss: 612.634033203125\n",
      "epoch: 67, test loss: 609.783447265625\n",
      "epoch: 68, test loss: 603.8134765625\n",
      "epoch: 69, test loss: 601.5797119140625\n",
      "epoch: 70, test loss: 605.20263671875\n",
      "epoch: 71, test loss: 601.589111328125\n",
      "epoch: 72, test loss: 602.562744140625\n",
      "epoch: 73, test loss: 599.4757690429688\n",
      "epoch: 74, test loss: 597.4292602539062\n",
      "epoch: 75, test loss: 602.3766479492188\n",
      "epoch: 76, test loss: 588.0733032226562\n",
      "epoch: 77, test loss: 598.8117065429688\n",
      "epoch: 78, test loss: 591.1197509765625\n",
      "epoch: 79, test loss: 595.966552734375\n",
      "epoch: 80, test loss: 591.684326171875\n",
      "epoch: 81, test loss: 588.0944213867188\n",
      "epoch: 82, test loss: 602.2584228515625\n",
      "epoch: 83, test loss: 597.0762329101562\n",
      "epoch: 84, test loss: 601.801025390625\n",
      "epoch: 85, test loss: 596.5152587890625\n",
      "epoch: 86, test loss: 592.3585205078125\n",
      "epoch: 87, test loss: 591.0293579101562\n",
      "epoch: 88, test loss: 583.8927001953125\n",
      "epoch: 89, test loss: 596.5897827148438\n",
      "epoch: 90, test loss: 588.86376953125\n",
      "epoch: 91, test loss: 595.368408203125\n",
      "epoch: 92, test loss: 592.8286743164062\n",
      "epoch: 93, test loss: 591.8264770507812\n",
      "epoch: 94, test loss: 591.3700561523438\n",
      "epoch: 95, test loss: 593.8020629882812\n",
      "epoch: 96, test loss: 593.7734985351562\n",
      "epoch: 97, test loss: 591.0943603515625\n",
      "epoch: 98, test loss: 589.5994873046875\n",
      "epoch: 99, test loss: 594.7915649414062\n",
      "epoch: 100, test loss: 588.6286010742188\n",
      "epoch: 101, test loss: 587.3468017578125\n",
      "epoch: 102, test loss: 583.32470703125\n",
      "epoch: 103, test loss: 583.728759765625\n",
      "epoch: 104, test loss: 589.130126953125\n",
      "epoch: 105, test loss: 586.4911499023438\n",
      "epoch: 106, test loss: 580.9979858398438\n",
      "epoch: 107, test loss: 591.853271484375\n",
      "epoch: 108, test loss: 589.186279296875\n",
      "epoch: 109, test loss: 583.0195922851562\n",
      "epoch: 110, test loss: 589.2623291015625\n",
      "epoch: 111, test loss: 584.9151000976562\n",
      "epoch: 112, test loss: 584.4722290039062\n",
      "epoch: 113, test loss: 581.2388916015625\n",
      "epoch: 114, test loss: 583.27587890625\n",
      "epoch: 115, test loss: 585.523193359375\n",
      "epoch: 116, test loss: 584.05078125\n",
      "epoch: 117, test loss: 587.4974975585938\n",
      "epoch: 118, test loss: 585.1732177734375\n",
      "epoch: 119, test loss: 580.8195190429688\n",
      "epoch: 120, test loss: 584.6534423828125\n",
      "epoch: 121, test loss: 584.6793823242188\n",
      "epoch: 122, test loss: 575.244873046875\n",
      "epoch: 123, test loss: 583.4700317382812\n",
      "epoch: 124, test loss: 580.0291137695312\n",
      "epoch: 125, test loss: 584.1172485351562\n",
      "epoch: 126, test loss: 582.3236694335938\n",
      "epoch: 127, test loss: 585.5906982421875\n",
      "epoch: 128, test loss: 581.0183715820312\n",
      "epoch: 129, test loss: 584.9107666015625\n",
      "epoch: 130, test loss: 588.7891845703125\n",
      "epoch: 131, test loss: 579.30078125\n",
      "epoch: 132, test loss: 575.0906372070312\n",
      "epoch: 133, test loss: 579.6109619140625\n",
      "epoch: 134, test loss: 585.4347534179688\n",
      "epoch: 135, test loss: 586.9691772460938\n",
      "epoch: 136, test loss: 579.0797119140625\n",
      "epoch: 137, test loss: 574.9205322265625\n",
      "epoch: 138, test loss: 580.6549072265625\n",
      "epoch: 139, test loss: 580.5017700195312\n",
      "epoch: 140, test loss: 578.6157836914062\n",
      "epoch: 141, test loss: 575.764892578125\n",
      "epoch: 142, test loss: 583.1057739257812\n",
      "epoch: 143, test loss: 570.3575439453125\n",
      "epoch: 144, test loss: 578.465576171875\n",
      "epoch: 145, test loss: 581.50830078125\n",
      "epoch: 146, test loss: 580.4220581054688\n",
      "epoch: 147, test loss: 580.234375\n",
      "epoch: 148, test loss: 576.5462646484375\n",
      "epoch: 149, test loss: 574.4584350585938\n",
      "epoch: 150, test loss: 582.3746948242188\n",
      "epoch: 151, test loss: 579.1109008789062\n",
      "epoch: 152, test loss: 575.4094848632812\n",
      "epoch: 153, test loss: 579.886474609375\n",
      "epoch: 154, test loss: 577.4270629882812\n",
      "epoch: 155, test loss: 581.057373046875\n",
      "epoch: 156, test loss: 579.18359375\n",
      "epoch: 157, test loss: 568.37255859375\n",
      "epoch: 158, test loss: 580.2260131835938\n",
      "epoch: 159, test loss: 565.739990234375\n",
      "epoch: 160, test loss: 578.6214599609375\n",
      "epoch: 161, test loss: 579.4531860351562\n",
      "epoch: 162, test loss: 578.8145751953125\n",
      "epoch: 163, test loss: 578.2785034179688\n",
      "epoch: 164, test loss: 579.7656860351562\n",
      "epoch: 165, test loss: 584.4169921875\n",
      "epoch: 166, test loss: 576.2479858398438\n",
      "epoch: 167, test loss: 572.1409301757812\n",
      "epoch: 168, test loss: 575.0565795898438\n",
      "epoch: 169, test loss: 571.6875610351562\n",
      "epoch: 170, test loss: 572.6854858398438\n",
      "epoch: 171, test loss: 578.4951171875\n",
      "epoch: 172, test loss: 578.2515869140625\n",
      "epoch: 173, test loss: 574.8856201171875\n",
      "epoch: 174, test loss: 564.44580078125\n",
      "epoch: 175, test loss: 577.5665283203125\n",
      "epoch: 176, test loss: 577.6953735351562\n",
      "epoch: 177, test loss: 578.0377807617188\n",
      "epoch: 178, test loss: 580.6314086914062\n",
      "epoch: 179, test loss: 569.2957763671875\n",
      "epoch: 180, test loss: 574.5662231445312\n",
      "epoch: 181, test loss: 581.9962768554688\n",
      "epoch: 182, test loss: 573.3773803710938\n",
      "epoch: 183, test loss: 578.3985595703125\n",
      "epoch: 184, test loss: 582.4764404296875\n",
      "epoch: 185, test loss: 578.981201171875\n",
      "epoch: 186, test loss: 573.9071044921875\n",
      "epoch: 187, test loss: 572.6290893554688\n",
      "epoch: 188, test loss: 579.9619140625\n",
      "epoch: 189, test loss: 573.9310302734375\n",
      "epoch: 190, test loss: 574.9439697265625\n",
      "epoch: 191, test loss: 571.8238525390625\n",
      "epoch: 192, test loss: 576.1442260742188\n",
      "epoch: 193, test loss: 574.4134521484375\n",
      "epoch: 194, test loss: 579.1522827148438\n",
      "epoch: 195, test loss: 577.7920532226562\n",
      "epoch: 196, test loss: 572.9457397460938\n",
      "epoch: 197, test loss: 575.083984375\n",
      "epoch: 198, test loss: 564.4114379882812\n",
      "epoch: 199, test loss: 574.8991088867188\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "for i in range(200):\n",
    "    model.load_state_dict(torch.load(f'model_state/model_epoch{i}_greater300.pth'))\n",
    "    test_losses.append(view_loss(model,process_features(test),torch.tensor(test_labels).to(torch.float32),criterion)/process_features(test).shape[0]*128)\n",
    "    print(f\"epoch: {i}, test loss: {view_loss(model, process_features(test), torch.tensor(test_labels).to(torch.float32), criterion)/process_features(test).shape[0]*128}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "963c9497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3dfc093a30>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(torch.Tensor.cpu(torch.tensor(test_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f43b33b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_state/model_epoch199_greater300.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07150e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([320, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3678/1078090879.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  predict_input = torch.tensor(process_features(competition_test)).to(device)\n"
     ]
    }
   ],
   "source": [
    "predict_input = torch.tensor(process_features(competition_test)).to(device)\n",
    "print(predict_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d14bf684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    predict_output = model(predict_input)\n",
    "    return predict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e49a258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c91364a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>TRAVEL_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>792.238525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>671.317749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>740.217896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>673.028931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>673.787048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>673.935425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7</td>\n",
       "      <td>746.509460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T8</td>\n",
       "      <td>823.881653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T9</td>\n",
       "      <td>684.157410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T10</td>\n",
       "      <td>746.034241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T11</td>\n",
       "      <td>664.980103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T12</td>\n",
       "      <td>803.843872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T13</td>\n",
       "      <td>774.805908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T14</td>\n",
       "      <td>975.007080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T15</td>\n",
       "      <td>803.261414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T16</td>\n",
       "      <td>814.392578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T17</td>\n",
       "      <td>764.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T18</td>\n",
       "      <td>853.902771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>T19</td>\n",
       "      <td>796.868103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>T20</td>\n",
       "      <td>812.811890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>T21</td>\n",
       "      <td>725.407227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>T22</td>\n",
       "      <td>888.554504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>T23</td>\n",
       "      <td>638.989136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>T24</td>\n",
       "      <td>798.360657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>T25</td>\n",
       "      <td>679.853394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>T26</td>\n",
       "      <td>710.697632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>T27</td>\n",
       "      <td>739.331116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>T28</td>\n",
       "      <td>797.383545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>T29</td>\n",
       "      <td>661.654358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>T30</td>\n",
       "      <td>791.518005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>T31</td>\n",
       "      <td>752.376892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>T32</td>\n",
       "      <td>668.978088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>T33</td>\n",
       "      <td>833.695129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>T34</td>\n",
       "      <td>861.468323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>T35</td>\n",
       "      <td>852.066040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>T36</td>\n",
       "      <td>780.001160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>T37</td>\n",
       "      <td>842.806824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>T38</td>\n",
       "      <td>689.752808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>T39</td>\n",
       "      <td>780.678284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>T40</td>\n",
       "      <td>683.464600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>T41</td>\n",
       "      <td>676.597229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>T42</td>\n",
       "      <td>775.640564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>T43</td>\n",
       "      <td>946.713623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>T44</td>\n",
       "      <td>719.089661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>T45</td>\n",
       "      <td>664.342957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>T46</td>\n",
       "      <td>697.856506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>T47</td>\n",
       "      <td>792.078369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>T48</td>\n",
       "      <td>796.162476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>T49</td>\n",
       "      <td>663.570923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>T50</td>\n",
       "      <td>650.734985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TRIP_ID  TRAVEL_TIME\n",
       "0       T1   792.238525\n",
       "1       T2   671.317749\n",
       "2       T3   740.217896\n",
       "3       T4   673.028931\n",
       "4       T5   673.787048\n",
       "5       T6   673.935425\n",
       "6       T7   746.509460\n",
       "7       T8   823.881653\n",
       "8       T9   684.157410\n",
       "9      T10   746.034241\n",
       "10     T11   664.980103\n",
       "11     T12   803.843872\n",
       "12     T13   774.805908\n",
       "13     T14   975.007080\n",
       "14     T15   803.261414\n",
       "15     T16   814.392578\n",
       "16     T17   764.003906\n",
       "17     T18   853.902771\n",
       "18     T19   796.868103\n",
       "19     T20   812.811890\n",
       "20     T21   725.407227\n",
       "21     T22   888.554504\n",
       "22     T23   638.989136\n",
       "23     T24   798.360657\n",
       "24     T25   679.853394\n",
       "25     T26   710.697632\n",
       "26     T27   739.331116\n",
       "27     T28   797.383545\n",
       "28     T29   661.654358\n",
       "29     T30   791.518005\n",
       "30     T31   752.376892\n",
       "31     T32   668.978088\n",
       "32     T33   833.695129\n",
       "33     T34   861.468323\n",
       "34     T35   852.066040\n",
       "35     T36   780.001160\n",
       "36     T37   842.806824\n",
       "37     T38   689.752808\n",
       "38     T39   780.678284\n",
       "39     T40   683.464600\n",
       "40     T41   676.597229\n",
       "41     T42   775.640564\n",
       "42     T43   946.713623\n",
       "43     T44   719.089661\n",
       "44     T45   664.342957\n",
       "45     T46   697.856506\n",
       "46     T47   792.078369\n",
       "47     T48   796.162476\n",
       "48     T49   663.570923\n",
       "49     T50   650.734985"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_mlp_predict = pd.read_csv('test_public.csv')\n",
    "embed_mlp_predict = embed_mlp_predict['TRIP_ID']\n",
    "predict_tensor = out.to('cpu').detach().numpy().flatten()\n",
    "embed_mlp_predict= pd.concat([embed_mlp_predict, pd.DataFrame(predict_tensor)], axis=1)\n",
    "embed_mlp_predict = embed_mlp_predict.rename(columns={0: 'TRAVEL_TIME'})\n",
    "embed_mlp_predict[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bf67f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874.71875"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_mlp_predict['TRAVEL_TIME'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5218f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_mlp_predict.to_csv('Embedding_MLP_199_greater300.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db9824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = process_features(train)\n",
    "print(a[:,0])\n",
    "embedding1 = torch.nn.Embedding(96, 10)\n",
    "embedding2 = torch.nn.Embedding()\n",
    "print(embedding(a[0,0].to(torch.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e5509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
